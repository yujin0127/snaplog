"""Snaplog server â€“ 3ë‹¨ê³„(ë¶„ì„â†’ì´ˆì•ˆâ†’ë³´ì •) + êµì°¨ê²€ì¦(ëª¨ë¸ ì´ì¤‘ìƒì„±)"""
from __future__ import annotations  # â† ë§¨ ìœ„ë¡œ!

from email_utils import (
    generate_verification_code,
    generate_reset_token,
    send_verification_email,
    send_password_reset_email
)

from auth_cosmos import (
    init_cosmos_db,
    create_user,
    authenticate_user,
    get_user_by_id,
    login_required,
    save_diary,
    get_user_diaries,
    get_diary_by_id,
    delete_diary,
    change_password,      # âœ… ì¶”ê°€!
    delete_user_account,
    save_verification_code,
    verify_code,
    save_reset_token,
    verify_reset_token,
    reset_password_with_token,
    init_verifications_container # âœ… ì¶”ê°€!
)
import os, re, json, random, traceback, time, io, base64, uuid
from threading import Lock
from flask import Flask, request, jsonify, send_file, render_template
from flask_cors import CORS
from openai import OpenAI, RateLimitError
from openai import APIConnectionError, APITimeoutError
from datetime import datetime, timedelta  # [ì¶”ê°€] timedelta
from werkzeug.utils import secure_filename

# ---------------- Flask ---------------

app = Flask(__name__)
CORS(app)

# CosmosDB ì´ˆê¸°í™” (ì„œë²„ ì‹œì‘ ì‹œ)
print("\nğŸ”„ CosmosDB ì—°ê²° ì‹œë„ ì¤‘...")
cosmos_initialized = init_cosmos_db()
if cosmos_initialized:
    print("âœ… CosmosDB ì—°ê²° ì„±ê³µ!")
    from auth_cosmos import init_verifications_container
    init_verifications_container()
else:
    print("âš ï¸  CosmosDB ì´ˆê¸°í™” ì‹¤íŒ¨. ì¸ì¦ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ì›ë³¸ ì €ì¥ ë””ë ‰í„°ë¦¬

UPLOAD_DIR = os.getenv("SNAPLOG_UPLOAD_DIR", os.path.join(os.path.dirname(os.path.abspath(__file__)), "uploads"))
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ---------------- OpenAI ----------------

API_KEY = os.getenv("OPENAI_OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
if not API_KEY:
    raise RuntimeError('OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. Windows: setx OPENAI_API_KEY "sk-..."')

client = OpenAI(api_key=API_KEY)

# ëª¨ë¸ ì„¤ì •

MODEL_VISION = "gpt-4o-mini"   # ì´ë¯¸ì§€ ë¶„ì„
MODEL_TEXT   = "gpt-4o-mini"   # ì´ˆì•ˆ 1ì°¨
ALT_TEXT_MODEL = os.getenv("OPENAI_ALT_TEXT_MODEL", "gpt-4o")  # ì´ˆì•ˆ 2ì°¨(ë™ì¼ í”„ë¡¬í¬íŠ¸)
MODERATION_MODEL = os.getenv("OPENAI_MODERATION_MODEL", "omni-moderation-latest")  # [ì¶”ê°€] í…ìŠ¤íŠ¸ ëª¨ë”ë ˆì´ì…˜

MAX_IMAGES   = 5
THROTTLE_SECONDS = float(os.getenv("OPENAI_THROTTLE_SECONDS", "0.5"))
MAX_WAIT_SECONDS = float(os.getenv("OPENAI_MAX_WAIT_SECONDS", "30"))
REQUEST_TIMEOUT = float(os.getenv("OPENAI_REQUEST_TIMEOUT", "30"))
_last_call_ts = 0.0
_throttle_lock = Lock()

# === Call-budget switches (ì¶”ê°€) ===
STAGE1_TOP_N = int(os.getenv("SNAPLOG_STAGE1_TOPN", "5"))  # Stage1ì— íˆ¬ì…í•  ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ (<= MAX_IMAGES)
ALT_SKIP_IF_LOW_FOOD = int(os.getenv("SNAPLOG_ALT_SKIP_IF_LOW_FOOD", "1"))  # ìŒì‹ ê°€ëŠ¥ì„± ë‚®ìœ¼ë©´ ALT ìŠ¤í‚µ
ALT_LOW_FOOD_THRESH = float(os.getenv("SNAPLOG_LOW_FOOD_THRESH", "0.4"))    # 0~1 ì‚¬ì´, ë‚®ì„ìˆ˜ë¡ ALT ë” ìì£¼ ìŠ¤í‚µ
REFINE_SKIP_IF_SHORT = int(os.getenv("SNAPLOG_REFINE_SKIP_IF_SHORT", "1"))  # ì´ˆì•ˆì´ ì§§ìœ¼ë©´ ë³´ì • ìŠ¤í‚µ
REFINE_MIN_CHARS = int(os.getenv("SNAPLOG_REFINE_MIN_CHARS", "280"))        # ì´ ê¸¸ì´ ë¯¸ë§Œì´ë©´ ë³´ì • ìƒëµ

def throttled_chat_completion(**kwargs):
    global _last_call_ts
    backoff = THROTTLE_SECONDS
    last_error: Exception | None = None
    total_wait = 0.0
    while total_wait <= MAX_WAIT_SECONDS:
        with _throttle_lock:
            wait = THROTTLE_SECONDS - (time.monotonic() - _last_call_ts)
        if wait > 0:
            time.sleep(wait)
            total_wait += wait

        retry_secs = THROTTLE_SECONDS
        with _throttle_lock:
            try:
                # ìš”ì²­ íƒ€ì„ì•„ì›ƒ ëª…ì‹œ
                resp = client.chat.completions.create(timeout=REQUEST_TIMEOUT, **kwargs)
                _last_call_ts = time.monotonic()
                return resp
            except (RateLimitError, APITimeoutError, APIConnectionError) as e:
                last_error = e
                msg = str(e) or ""
                retry_ms_match = re.search(r"try again in\s+(\d+)\s*ms", msg, re.I)
                if retry_ms_match:
                    retry_secs = max(retry_secs, float(retry_ms_match.group(1)) / 1000.0)
                else:
                    retry_secs = max(retry_secs, backoff)
                _last_call_ts = time.monotonic() + retry_secs

        time.sleep(retry_secs)
        total_wait += retry_secs
        backoff = min(backoff * 2, THROTTLE_SECONDS * 16)
    if last_error is not None:
        raise last_error
    raise RuntimeError("Rate limit/timeout exhausted")

# ---------------- ê¸ˆì§€/ì •ë¦¬ ìœ í‹¸ ----------------

FILE_RE = re.compile(r"\b[\w\-]+\.(jpg|jpeg|png|webp|heic)\b", re.I)
DATE_RE = re.compile(r"\b20\d{2}\s*[-.]?\s*\d{1,2}\s*[-.]?\s*\d{1,2}\b|\b20\d{2}\s*ë…„\s*\d{1,2}\s*ì›”\s*\d{1,2}\s*ì¼\b")

BAN_WORDS_INLINE = [
    "ì‚¬ì§„", "ì´ë¯¸ì§€", "ì´¬ì˜", "ìº¡ì²˜", "ì°ì€",
    "ë¯¸ìƒ", "í™•ì¸ë˜ì§€ ì•ŠìŒ", "unknown", "í˜„ì¬ ì‹œê°",
]

def clean_inline(s: str) -> str:
    if not s:
        return ""
    t = re.sub(r"\s+", " ", s).strip()
    t = FILE_RE.sub("", t)
    t = DATE_RE.sub("", t)
    for w in BAN_WORDS_INLINE:
        t = t.replace(w, "")
    return t.strip()

# ----------------êµì²´ ìœ í‹¸ í•¨ìˆ˜ ì¶”ê°€----------------

def replace_proper_nouns_if_no_visible_text(analysis: dict, draft: str) -> str:
    """
    visible_textë‚˜ ëª…í™•í•œ ì¦ê±°ê°€ ì—†ì„ ê²½ìš°,
    ì´ˆì•ˆ ë‚´ ìŒì‹/ì§€ëª… ê³ ìœ ëª…ì‚¬ë¥¼ ì¼ë°˜ì–´ë¡œ êµì²´í•œë‹¤.
    """
    if not analysis or not draft:
        return draft

    frames = analysis.get("frames") or []
    any_visible_text = any(f.get("visible_text", "").strip() for f in frames)
    if any_visible_text:
        return draft  # ì‹¤ì œ ê¸€ìê°€ ë³´ì˜€ë‹¤ë©´ ê·¸ëŒ€ë¡œ ë‘ 

    # êµì²´ ì‚¬ì „ (í•„ìš”ì‹œ í™•ì¥ ê°€ëŠ¥)
    replace_map = {
        r"ìŠ¤íƒ€ë²…ìŠ¤": "ì¹´í˜",
        r"ì´ë””ì•¼": "ì¹´í˜",
        r"íˆ¬ì¸": "ì¹´í˜",
        r"ë˜í‚¨": "ì¹´í˜",
        r"íŒŒë¦¬ë°”ê²Œëœ¨": "ë¹µì§‘",
        r"ë§¥ë„ë‚ ë“œ": "íŒ¨ìŠ¤íŠ¸í‘¸ë“œì ",
        r"ë¡¯ë°ë¦¬ì•„": "íŒ¨ìŠ¤íŠ¸í‘¸ë“œì ",
    }

    text = draft
    for pat, rep in replace_map.items():
        text = re.sub(pat, rep, text, flags=re.I)

    return text

# ---- ë³´ê³ ì„œí˜•/ë‚˜ì—´/ì˜¤íƒ€/ì‹œì œ/ì‹œì /ì‹œì /ë¦¬ë“¬/ê°ì • êµì • ----
GENERIC_LIST_RE = re.compile(r"(êµ­|ì°Œê°œ|íƒ•|ë©´|ë°¥|ë°˜ì°¬|ê¹€ì¹˜)(?:[ ,ê³¼ì™€ë°]+(êµ­|ì°Œê°œ|íƒ•|ë©´|ë°¥|ë°˜ì°¬|ê¹€ì¹˜))+", re.U)
def simplify_food_enumeration(text: str) -> str:
    if not text: return text
    return GENERIC_LIST_RE.sub("ë°˜ì°¬ ëª‡ ê°€ì§€", text)

# ---------------- ì¹´í…Œê³ ë¦¬ ----------------
FOOD_RE = re.compile(r"(ìŒì‹|ì‹ë‹¹|ì¹´í˜|ìš”ë¦¬|coffee|cafe|cake|bread|meal|lunch|dinner|brunch|dessert|ì»¤í”¼|ë¹µ|ì¼€ì´í¬|ë””ì €íŠ¸)", re.I)
def decide_category_from_lines(lines: list[str]) -> str:
    if len(lines) == 1:
        return "food_single" if FOOD_RE.search(lines[0]) else "general_single"
    return "journey_multi"

# ============ ë‹¤ì–‘í•œ ì‹œê° í¬ë§· íŒŒì„œ ============
def _parse_any_dt(x: str | int | float) -> datetime | None:
    if x is None:
        return None
    # epoch-like
    if isinstance(x, (int, float)):
        try:
            ts = float(x)
            if ts > 10_000_000_000:  # ms
                ts /= 1000.0
            return datetime.fromtimestamp(ts)
        except Exception:
            pass
    xs = str(x).strip()
    if re.fullmatch(r"\d{10,13}", xs):
        try:
            ts = int(xs)
            if len(xs) >= 13:
                ts = ts / 1000.0
            return datetime.fromtimestamp(ts)
        except Exception:
            pass
    if xs.endswith("Z"):
        xs = xs[:-1] + "+00:00"
    fmts = (
        "%Y-%m-%d %H:%M:%S%z",
        "%Y-%m-%d %H:%M%z",
        "%Y-%m-%dT%H:%M:%S.%f%z",
        "%Y-%m-%dT%H:%M:%S%z",
        "%Y-%m-%dT%H:%M%z",
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%d %H:%M",
        "%Y-%m-%d",
        "%Y.%m.%d %H:%M:%S",
        "%Y.%m.%d %H:%M",
        "%Y.%m.%d.",
        "%Y.%m.%d. %H:%M:%S",
        "%Y.%m.%d. %H:%M",
        "%Y/%m/%d %H:%M:%S",
        "%Y/%m/%d %H:%M",
        "%Y-%m-%d-%H-%M-%S",
        "%Y.%m.%d-%H-%M-%S",
        "%Y:%m:%d %H:%M:%S",
        "%Y%m%d_%H%M%S",
        "%Y%m%d%H%M%S",
        "%Y-%m-%d %H:%M:%S.%f",
    )
    for fmt in fmts:
        try:
            return datetime.strptime(xs, fmt)
        except Exception:
            pass
    try:
        return datetime.fromisoformat(xs)
    except Exception:
        return None

# ============ íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ/ì‹œê°„ ì¶”ì¶œ ============
_FILENAME_DT_PATTERNS = [
    re.compile(r".*?(?P<y>\d{4})(?P<m>\d{2})(?P<d>\d{2})[_\- ](?P<H>\d{2})(?P<M>\d{2})(?P<S>\d{2}).*", re.I),
    re.compile(r".*?(?P<y>\d{4})[-_.](?P<m>\d{2})[-_.](?P<d>\d{2})[-_ ](?P<H>\d{2})[-_.:](?P<M>\d{2})(?:[-_.:](?P<S>\d{2}))?.*", re.I),
    re.compile(r".*?(?P<y>\d{4})[.](?P<m>\d{2})[.](?P<d>\d{2})[ _](?P<H>\d{2})[.](?P<M>\d{2})(?:[.](?P<S>\d{2}))?.*", re.I),
    re.compile(r".*?(?P<y>\d{4})(?P<m>\d{2})(?P<d>\d{2})[_-](?P<H>\d{2})(?P<M>\d{2})(?P<S>\d{2}).*", re.I),
]

def _dt_from_filename(name: str) -> datetime | None:
    if not name:
        return None
    base = os.path.basename(name)
    for pat in _FILENAME_DT_PATTERNS:
        m = pat.match(base)
        if m:
            try:
                y = int(m.group("y")); mth = int(m.group("m")); d = int(m.group("d"))
                H = int(m.group("H")); M = int(m.group("M")); S = int(m.group("S") or 0)
                return datetime(y, mth, d, H, M, S)
            except Exception:
                continue
    return None

# ============ EXIF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (bytes ê¸°ì¤€) ============
def _read_exif_datetime_from_bytes(raw: bytes) -> datetime | None:
    """ì´ë¯¸ì§€ ë°”ì´íŠ¸ì—ì„œ EXIF datetime ì¶”ì¶œ â†’ datetime ê°ì²´ ë°˜í™˜"""
    try:
        from PIL import Image
        from PIL.ExifTags import TAGS
        img = Image.open(io.BytesIO(raw))
        exif = getattr(img, "_getexif", lambda: None)() or {}
        for tag_id, value in exif.items():
            tag = TAGS.get(tag_id, tag_id)
            if tag in ("DateTimeOriginal", "DateTime"):
                dt = _parse_any_dt(str(value))
                if dt:
                    return dt
        info = getattr(img, "info", {}) or {}
        for k in ("Creation Time", "date:create", "date:modify"):
            v = info.get(k)
            if v:
                dt = _parse_any_dt(str(v))
                if dt:
                    return dt
    except Exception as e:
        print(f"EXIF ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    return None

# ---------------- ë‚ ì§œ ê²½ê³„ ìœ í‹¸ + ìŠ¤í‹°ì²˜ ----------------
def _day_break_positions(date_sequence: list[str]) -> list[tuple[int,int]]:
    if not date_sequence or len(date_sequence) < 2:
        return []
    out = []
    def _to_date(x):
        try:
            return datetime.fromisoformat(str(x)).date()
        except Exception:
            return None
    for i in range(1, len(date_sequence)):
        a = _to_date(date_sequence[i-1]); b = _to_date(date_sequence[i])
        if a and b and a != b:
            out.append((i+1, (b - a).days))
    return out

def _label_for_days(diff: int) -> str:
    if diff <= 0: return ""
    if diff == 1: return "ë‹¤ìŒ ë‚ , "
    if diff == 2: return "ì´í‹€ ë’¤, "
    if diff == 3: return "ì‚¬í˜ ë’¤, "
    return f"{diff}ì¼ ë’¤, "

def compose_from_frames(analysis: dict) -> str:
    frames = (analysis or {}).get("frames") or []
    if not frames:
        return ""
    breaks = {pos: diff for (pos, diff) in _day_break_positions((analysis or {}).get("date_sequence") or [])}
    pieces = []
    for idx, f in enumerate(frames, start=1):
        if idx in breaks:
            pieces.append(_label_for_days(breaks[idx]))
        s = (f.get("summary") or "").strip()
        io = f.get("indoor_outdoor") or ""
        ph = f.get("place_hint") or ""
        frag = []
        if ph: frag.append(f"{ph}ì—ì„œ")
        if s: frag.append(s)
        else:
            if io == "indoor": frag.append("ì‹¤ë‚´ ì¥ë©´ì„ ì ì‹œ ì‚´íˆë‹¤")
            elif io == "outdoor": frag.append("ë°”ê¹¥ ì¥ë©´ì„ ì ì‹œ ë°”ë¼ë´¤ë‹¤")
            else: frag.append("ì¥ë©´ì„ ì ì‹œ ë°”ë¼ë´¤ë‹¤")
        sent = " ".join(x for x in frag if x).strip()
        if not sent.endswith("."): sent += "."
        pieces.append(sent)
    text = " ".join(pieces)
    return clean_inline(soften_report_tone(text))

_TIME_SHIFT_PAT = re.compile(r"(ë‹¤ìŒ\s*ë‚ |ì´í‹€\s*ë’¤|ì‚¬í˜\s*ë’¤|\d+\s*ì¼\s*ë’¤|ë©°ì¹ \s*í›„)", re.I)

# ======== íƒœê·¸ ê¸°ë°˜ ì¬ë°°ì—´ ë³´ì •ê¸° ========
_TAG_RE = re.compile(r"</?f(\d+)>", re.I)

def _reorder_by_tags(text: str, n_frames: int, date_sequence: list[str]) -> str | None:
    if not text or n_frames <= 0:
        return None
    blocks = {}
    for i in range(1, n_frames + 1):
        m = re.search(rf"<f{i}>(.*?)</f{i}>", text, re.I | re.S)
        if not m: return None
        blk = m.group(1).strip()
        if not blk: return None
        blocks[i] = blk
    breaks = {pos: diff for (pos, diff) in _day_break_positions(date_sequence or [])}
    out_parts = []
    for i in range(1, n_frames + 1):
        if i in breaks:
            out_parts.append(_label_for_days(breaks[i]))
        seg = blocks[i].strip()
        if i in breaks and _TIME_SHIFT_PAT.match(seg):
            out_parts.append(seg)
        else:
            out_parts.append(seg)
    out = " ".join(out_parts).strip()
    out = _TAG_RE.sub("", out)
    return clean_inline(out)

# ---------------- [ì¶”ê°€] ë‚ ì§œ ê¸°ì¤€ ì‹œí”„íŠ¸ ìœ í‹¸ ----------------
def _parse_date_only(s: str | None):
    if not s:
        return None
    try:
        dt = _parse_any_dt(s)
        return dt.date() if dt else None
    except Exception:
        return None

def _shift_date_sequence(orig_seq: list[str], target_date_str: str) -> list[str]:
    """
    orig_seqì˜ ì²« ìœ íš¨ ë‚ ì§œë¥¼ anchorë¡œ í•˜ì—¬ ìƒëŒ€ ì¼ìˆ˜ ì°¨ì´ë¥¼ ìœ ì§€í•œ ì±„
    ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ target_dateë¡œ í‰í–‰ ì´ë™í•œë‹¤.
    """
    td = _parse_date_only(target_date_str)
    if not td or not orig_seq:
        return orig_seq

    def _to_date(x):
        try:
            return datetime.fromisoformat(str(x)).date()
        except Exception:
            return None

    base = None
    for d in orig_seq:
        dd = _to_date(d)
        if dd:
            base = dd
            break

    if base is None:
        return [td.isoformat() for _ in orig_seq]

    deltas = []
    for d in orig_seq:
        dd = _to_date(d)
        deltas.append((dd - base).days if dd else 0)

    return [(td + timedelta(days=k)).isoformat() for k in deltas]

# ---------------- ë¶„ì„ ê²°ê³¼ í›„ì²˜ë¦¬: ìŒì‹ í›„ë³´ ìœµí•© ----------------
def fuse_food_candidates(analysis: dict) -> dict:
    fused = {}  # name -> {'score_sum':..., 'hits':..., 'evidence':set()}
    frames = (analysis or {}).get("frames") or []
    for f in frames:
        fs = f.get("food_structured") or {}
        for c in fs.get("main_dish_candidates") or []:
            name = (c.get("name") or "").strip()
            if not name:
                continue
            conf = float(c.get("confidence") or 0.0)
            ev = tuple(c.get("evidence") or [])
            if name not in fused:
                fused[name] = {"score_sum": 0.0, "hits": 0, "evidence": set()}
            fused[name]["score_sum"] += conf
            fused[name]["hits"] += 1
            fused[name]["evidence"].update(ev)
    out = []
    for name, v in fused.items():
        out.append({
            "name": name,
            "global_conf": v["score_sum"] / max(v["hits"], 1),
            "frames_support": v["hits"],
            "evidence_uniq": sorted(v["evidence"]),
        })
    out.sort(key=lambda x: (x["global_conf"], x["frames_support"]), reverse=True)
    return {"global_candidates": out}

# --------- ìŒì‹ ê°€ëŠ¥ì„± ìŠ¤ì½”ì–´ëŸ¬ (ì¶”ê°€) ----------
def _food_likelihood_score(analysis: dict | None) -> float:
    """
    0.0~1.0. í”„ë ˆì„ì˜ has_food, elements, food_fusionë¥¼ ì¢…í•©í•´ ê°„ë‹¨ ìŠ¤ì½”ì–´.
    - ë‹¤ì¤‘ì‚¬ì§„ì—ì„œë„ ê³„ì‚°ì€ í•˜ì§€ë§Œ, ë‹¤ì¤‘ì‚¬ì§„ì—ì„œëŠ” food_structuredë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
      'ALT ìŠ¤í‚µ ì—¬ë¶€' íŒë‹¨ì—ë§Œ ì“´ë‹¤.
    """
    if not analysis:
        return 0.0
    frames = analysis.get("frames") or []
    if not frames:
        return 0.0

    # 1) has_food ë¹„ìœ¨
    has_food_ratio = sum(1 for f in frames if f.get("has_food") is True) / max(len(frames), 1)

    # 2) elements í‚¤ì›Œë“œ íŒíŠ¸
    KW = ("ìŒë£Œ","ì»µ","ì¼€ì´í¬","ë¹µ","ë””ì €íŠ¸","ì ‘ì‹œ","ê·¸ë¦‡","ì “ê°€ë½","í¬í¬","ìƒëŸ¬ë“œ","ì´ˆë°¥","ë¼ë²¨","ë©”ë‰´")
    kw_hits = 0
    total_items = 0
    for f in frames:
        els = f.get("elements") or []
        total_items += len(els)
        kw_hits += sum(1 for x in els if any(k in x for k in KW))
    kw_ratio = (kw_hits / total_items) if total_items else 0.0

    # 3) food_fusion ì‹ ë¢°ë„
    fusion = (analysis or {}).get("food_fusion") or {}
    cands = fusion.get("global_candidates") or []
    top_conf = cands[0]["global_conf"] if cands else 0.0

    # ê°€ì¤‘ í‰ê· (ë‹¨ìˆœ)
    return 0.5 * has_food_ratio + 0.3 * kw_ratio + 0.2 * float(top_conf)

# --------- ì•ˆì „ í•„í„° (ì¶”ê°€) ----------
def is_content_safe_for_diary(analysis: dict | None) -> tuple[bool, dict]:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¼ê¸° í…ìŠ¤íŠ¸ ìƒì„± ì „, ì•ˆì „ì„± ì²´í¬.
    - frames.summary / elements / visible_textë¥¼ ëª¨ì•„ì„œ ëª¨ë”ë ˆì´ì…˜ APIì— ë³´ëƒ„
    - ë¬¸ì œê°€ ìˆìœ¼ë©´ False ë°˜í™˜
    """
    if not analysis:
        return True, {"reason": "no_analysis"}

    frames = analysis.get("frames") or []
    if not frames:
        return True, {"reason": "no_frames"}

    texts: list[str] = []
    for f in frames:
        s = f.get("summary")
        if isinstance(s, str):
            texts.append(s)
        els = f.get("elements")
        if isinstance(els, list):
            texts.extend(str(x) for x in els if x)
        vt = f.get("visible_text")
        if isinstance(vt, str):
            texts.append(vt)

    joined = " ".join(clean_inline(x) for x in texts if x).strip()
    if not joined:
        return True, {"reason": "empty_text"}

    try:
        resp = client.moderations.create(
            model=MODERATION_MODEL,
            input=joined[:4000],
        )
        result = resp.results[0]
        flagged = bool(getattr(result, "flagged", False))
        categories = getattr(result, "categories", {})
        return (not flagged), {
            "flagged": flagged,
            "categories": categories,
        }
    except Exception as e:
        # ëª¨ë”ë ˆì´ì…˜ ì‹¤íŒ¨ ì‹œì—ëŠ” ì¼ë‹¨ í†µê³¼ì‹œí‚¤ë˜, ë””ë²„ê·¸ ì •ë³´ë§Œ ë‚¨ê¹€
        return True, {"error": str(e)}

# --------- ìŒì‹-dominant multi íŒë³„ (ì¶”ê°€) ----------
def is_food_dominant_multi(analysis: dict | None) -> bool:
    if not analysis:
        return False
    frames = analysis.get("frames") or []
    if len(frames) < 2:
        return False

    has_food_ratio = sum(1 for f in frames if f.get("has_food") is True) / len(frames)
    places = { (f.get("place_hint") or "").strip() for f in frames if f.get("place_hint") }
    place_variety = len(places)
    movement = (analysis.get("global") or {}).get("movement")

    return (
        has_food_ratio >= 0.8 and
        place_variety <= 2 and
        movement in (None, "", "ì—†ìŒ", "ë¶ˆëª…")
    )

# --------- multi ìŒì‹ ì„¸íŠ¸ìš© food_structured ë³´ê°• (ì¶”ê°€) ----------
def enrich_food_structured_for_multi(analysis: dict | None,
                                     images: list | None = None,
                                     photos_summary: list | None = None) -> dict | None:
    """
    ë‹¤ì¤‘ ì´ë¯¸ì§€ ì„¸íŠ¸ ì¤‘ ìŒì‹-dominantì¸ ê²½ìš°,
    ê° has_food í”„ë ˆì„ì— ëŒ€í•´ ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„ì„ ì¬ì‚¬ìš©í•´ food_structured/visible_textë¥¼ ì±„ìš´ë‹¤.
    - ê¸°ì¡´ analyze_imagesì˜ ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ê¸°(í”„ë¡¬í”„íŠ¸)ë¥¼ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©í•˜ê¸° ìœ„í•´
      ë‚´ë¶€ì ìœ¼ë¡œ analyze_images([data_url])ë¥¼ í˜¸ì¶œí•œë‹¤.
    - prompts, ê¸°ì¡´ ë¡œì§ì„ ë³€ê²½í•˜ì§€ ì•Šê³  'ì¶”ê°€ í˜¸ì¶œ'ë§Œ ìˆ˜í–‰.
    """
    if not analysis:
        return analysis
    frames = analysis.get("frames") or []
    if not frames:
        return analysis

    sorted_images = analysis.get("sorted_images") or []
    if not sorted_images or len(sorted_images) != len(frames):
        return analysis

    for idx, f in enumerate(frames):
        if not f.get("has_food"):
            continue
        if f.get("food_structured"):
            continue
        if idx >= len(sorted_images):
            continue

        img_data_url = sorted_images[idx]
        try:
            sub_analysis = analyze_images([img_data_url], photos_summary=None)
        except Exception as e:
            print(f"[enrich_food_structured_for_multi] sub analyze_images ì‹¤íŒ¨ idx={idx}: {e}")
            continue

        if not sub_analysis:
            continue
        sub_frames = sub_analysis.get("frames") or []
        if not sub_frames:
            continue
        sub_f = sub_frames[0]
        fs = sub_f.get("food_structured")
        if fs:
            f["food_structured"] = fs
        if not f.get("visible_text") and sub_f.get("visible_text"):
            f["visible_text"] = sub_f["visible_text"]

    analysis["food_fusion"] = fuse_food_candidates(analysis)
    return analysis

# ---------------- 1) ë¶„ì„: ì´ë¯¸ì§€ â†’ êµ¬ì¡°í™” JSON ----------------
def analyze_images(images: list[str] | list[dict], photos_summary: list[dict] | None = None) -> dict | None:
    """
    ë‹¹ì‹ ì€ ì‚¬ì§„ì„ ì„¸ë°€í•˜ê²Œ ë¶„ì„í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
    ê° ì‚¬ì§„ì—ì„œ ë³´ì´ëŠ” ë‚´ìš©(ìŒì‹, ë°°ê²½, ì‚¬ëŒ ë“±)ì„ ìš”ì•½í•˜ê³ ,
    í…ìŠ¤íŠ¸(ë©”ë‰´íŒ, ìƒí‘œ, ë¼ë²¨ ë“±)ê°€ ì‹¤ì œë¡œ ë³´ì´ëŠ”ì§€ ì—¬ë¶€ì™€ ë‚´ìš©ì„ ëª…ì‹œì ìœ¼ë¡œ ê¸°ìˆ í•˜ì„¸ìš”.
    ê·¸ë¦¬ê³  ê° ì‚¬ì§„ì— ëŒ€í•´ ì‹¤ë‚´/ì‹¤ì™¸, ì‹œê°„ë‹¨ì„œ, ì¥ì†Œë‹¨ì„œ, íë¦„ë‹¨ì„œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
    """
    if not images:
        return None

    images_with_time = []
    ordering_debug = []
    for idx, img in enumerate(images[:MAX_IMAGES]):
        img_data = None
        dt = None
        src = "unknown"

        if isinstance(img, dict):
            img_data = img.get("data") or img.get("url") or ""
            cand_img_keys = ["order_ts", "shotAt", "takenAt", "timestamp", "time", "fileCreatedAt"]
            client_ts = next((img.get(k) for k in cand_img_keys if img.get(k) is not None), None)
            if client_ts is not None:
                dt = _parse_any_dt(client_ts)
                if dt: src = "pre_extracted"
            if dt is None:
                name = img.get("filename") or img.get("name") or img.get("originalName") or ""
                dt_name = _dt_from_filename(name)
                if dt_name:
                    dt = dt_name; src = "filename"
        else:
            img_data = img

        if dt is None and photos_summary and idx < len(photos_summary):
            ps = photos_summary[idx] or {}
            cand_ps_keys = ["time","takenAt","timestamp","fileCreatedAt","createdAt","created_at","sentAt","sent_at","messageTime","message_time","kakaoTime","kakao_time"]
            ps_time = next((ps.get(k) for k in cand_ps_keys if ps.get(k)), None)
            if ps_time:
                dt_ps = _parse_any_dt(ps_time)
                if dt_ps: dt = dt_ps; src = "photosSummary"

        if dt is None and isinstance(img_data, str) and img_data and img_data.startswith("data:image"):
            try:
                image_data = img_data.split(",")[1] if "," in img_data else img_data
                img_bytes = base64.b64decode(image_data)
                dt_exif = _read_exif_datetime_from_bytes(img_bytes)
                if dt_exif: dt = dt_exif; src = "exif_fallback"
            except Exception as e:
                print(f"[{idx}] data URL EXIF ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        images_with_time.append({
            "data": img_data,
            "original_index": idx,
            "datetime": dt,
            "date_iso": dt.date().isoformat() if dt else ""
        })
        ordering_debug.append({"i": idx, "source": src, "parsed": dt.isoformat() if dt else ""})
        print(f"[analyze_images] idx={idx}, source={src}, dt={dt.isoformat() if dt else 'None'}")

    images_with_time.sort(key=lambda x: (
        x["datetime"] is None,
        x["datetime"] if x["datetime"] else datetime.max,
        x["original_index"]
    ))
    sorted_images = [item["data"] for item in images_with_time]
    date_info_iso = [item["date_iso"] for item in images_with_time]

    sys = "ë‹¹ì‹ ì€ ì‚¬ì§„ì„ ì‚¬ì‹¤ëŒ€ë¡œ ê¸°ë¡í•˜ëŠ” ê´€ì°°ìì…ë‹ˆë‹¤."

    # ë‹¨ì¼/ë‹¤ì¤‘ ë¶„ê¸°: ë‹¨ì¼ì€ food_structured í¬í•¨, ë‹¤ì¤‘ì€ ì œì™¸
    if len(sorted_images) == 1:
        prompt = (
            "ì•„ë˜ ì´ë¯¸ì§€ë¥¼ **ì¶”ì¸¡ ì—†ì´** ê´€ì°°í•´ JSONìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n"
            "- ë©”íƒ€í‘œí˜„(ì‚¬ì§„/ì´ë¯¸ì§€/ì´¬ì˜/ë¬¼ê±´ ë“±) ê¸ˆì§€, íŒŒì¼ëª…/ë‚ ì§œ ì–¸ê¸‰ ê¸ˆì§€\n"
            "- ì„±ë³„Â·ì¸ì›ìˆ˜ ì¶”ì • ê¸ˆì§€, ë¶ˆí™•ì‹¤í•˜ë©´ ìƒëµ\n"
            "- ê° ì‚¬ì§„ì— ëŒ€í•´: í•µì‹¬ í•œì¤„(summary), ë³´ì´ëŠ” ìš”ì†Œ(elements), ì‹¤ë‚´/ì‹¤ì™¸(indoor_outdoor), ì‹œê°„ë‹¨ì„œ(time_hint: ì˜¤ì „/ì˜¤í›„/ì €ë…/ë°¤ ë“±), ì¥ì†Œë‹¨ì„œ(place_hint: ë³´ì´ë©´ í•œ ë‹¨ì–´), ê³µê°„ê´€ê³„(space_relations: ë°°ê²½Â·ê±°ë¦¬ê°Â·ì‹œì„ ë°©í–¥ ë“± ê°„ëµíˆ), íë¦„ë‹¨ì„œ(flow: ì´ë™/ë¨¸ë¬´ë¦„ ë“±)\n"
            "- 'ë³´ì´ëŠ” ê²ƒë§Œ' ê°„ë‹¨íˆ\n"
            "- í‰ê°€/ì¶”ìƒ í¬í˜„ ê¸ˆì§€ : 'ì‹ì‚¬ê°€ ì¤€ë¹„ë˜ì–´ ìˆì—ˆë‹¤/ì‹ìš•ì„ ìê·¹'ê°™ì€ í•´ì„ ë¬¸êµ¬ ê¸ˆì§€. ë³´ì´ëŠ” ì‚¬ì‹¤ë§Œ.\n"
            "- ìŒì‹Â·ì¥ì†Œ **ê³ ìœ ëª…ì‚¬(ë©”ë‰´/ì§€ëª…)**ëŠ” **ë³´ì¼ ë•Œë§Œ** ê¸°ë¡.\n"
            "- ìŒì‹ ì¸ì‹ì€ **ë³´ì´ëŠ” í˜•ìƒÂ·ìƒ‰Â·í† í•‘Â·ìš©ê¸°Â·ì¬ë£Œ** ê·¼ê±°ë¡œë§Œ íŒë‹¨. ì¶”ì¸¡ ê¸ˆì§€.\n"
            "- ì•¼ì™¸/ê°€ì •/ì¹´í˜ ì¶”ì¸¡ ê¸ˆì§€. ë³´ì´ëŠ” ë‹¨ì„œë§Œ ì‚¬ìš©.\n"
            "- í•œì‹ ìƒì°¨ë¦¼ì´ë‚˜ ë°˜ì°¬ë¥˜ëŠ” 'ë°˜ì°¬' í‘œê¸°. ëª…í™•í•œ ëª…ì¹­ì´ ë³´ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©.\n"
            "- visible_text: ì‚¬ì§„ ì•ˆì— ì‹¤ì œë¡œ ë³´ì´ëŠ” ê¸€ì. ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´.\n"
            "- has_foodì´ falseë©´ food_structuredë¥¼ **ìƒëµ**.\n"
            "- has_foodì´ trueë¼ë„ ë¹„ì–´ ìˆëŠ” ë°°ì—´/í•„ë“œëŠ” ìƒëµí•˜ê³  í•„ìš”í•œ í•­ëª©ë§Œ ê¸°ë¡.\n"
            "- main_dish_candidatesëŠ” ìƒìœ„ 1ê°œ, evidenceëŠ” ìµœëŒ€ 2ê°œ ë¬¸ì¥.\n\n"
            "JSON í˜•ì‹:\n"
            "{\n"
            "  \"frames\": [\n"
            "    {\n"
            "      \"index\": 1,\n"
            "      \"summary\": \"...\",                       \n"
            "      \"elements\": [\"...\"],                    \n"
            "      \"indoor_outdoor\": \"indoor|outdoor|unknown\",\n"
            "      \"time_hint\": \"ì˜¤ì „|ì •ì˜¤|ì˜¤í›„|ì €ë…|ë°¤|ë¶ˆëª…\",\n"
            "      \"place_hint\": \"ë³´ì´ë©´ í•œ ë‹¨ì–´\",\n"
            "      \"space_relations\": \"ìµœëŒ€ 20ì\",\n"
            "      \"visible_text\": \"ë³´ì´ëŠ” í…ìŠ¤íŠ¸(ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)\",\n"
            "      \"flow\": \"ì´ë™|ë¨¸ë¬´ë¦„|ë¶ˆëª…\",\n"
            "      \"has_food\": true|false,\n"
            "      \"food_structured\": {\n"
            "        \"serving_style\": \"ë‹¨í’ˆ|ë®ë°¥|ë¹„ë¹”|êµ­ë¬¼|ì‚¬ì´ë“œ|ë¶ˆëª…\",\n"
            "        \"starch_base\": \"ë°¥|ë©´|ë–¡|ë¹µ|ì—†ìŒ|ë¶ˆëª…\",\n"
            "        \"container\": \"ì ‘ì‹œ|ê·¸ë¦‡|íŠ¸ë ˆì´|ë„ì‹œë½|ë¶ˆëª…\",\n"
            "        \"sauce\": {\"present\": true|false, \"color\": \"ë¹¨ê°•|ê°ˆìƒ‰|ë…¸ë‘|ì´ˆë¡|ê²€ì •|í°ìƒ‰|íˆ¬ëª…|ë¶ˆëª…\", \"form\": \"ì½”íŒ…|ì›…ë©ì´|ê³ë“¤ì„|êµ­ë¬¼|ë¶ˆëª…\"},\n"
            "        \"shape_cues\": [\"ì˜ˆ: ì›í†µí˜•\", \"ì˜ˆ: ë©´ë°œ\"],\n"
            "        \"surface_cues\": [\"ì˜ˆ: ìœ ê´‘ ì†ŒìŠ¤\", \"ì˜ˆ: íŠ€ê¹€ì˜·\"],\n"
            "        \"ingredients_visible\": [\"ì˜ˆ: ê°€ì§€\", \"ì˜ˆ: ì–‘íŒŒ\"],\n"
            "        \"main_dish_candidates\": [\n"
            "          {\n"
            "            \"name\": \"í›„ë³´ëª…(ë©”ë‰´íŒì— ë³´ì´ë©´ ê·¸ëŒ€ë¡œ)\",\n"
            "            \"confidence\": 0.0,\n"
            "            \"evidence\": [\"í˜•ìƒ ë‹¨ì„œ 1\", \"ìƒ‰/ìš©ê¸° ë‹¨ì„œ 1\"]\n"
            "          }\n"
            "        ]\n"
            "      }\n"
            "    }\n"
            "  ],\n"
            "  \"global\": {\"dominant_time\": \"ì˜¤ì „|ì •ì˜¤|ì˜¤í›„|ì €ë…|ë°¤|ë¶ˆëª…\", \"movement\": \"ìˆìŒ|ì—†ìŒ|ë¶ˆëª…\"}\n"
            "}\n"
            "**ì¤‘ìš”**: ì…ë ¥ëœ ì´ë¯¸ì§€ ìˆœì„œëŠ” **ì´¬ì˜ì‹œê° ì˜¤ë¦„ì°¨ìˆœ**ì…ë‹ˆë‹¤. ê·¸ ìˆœì„œë¥¼ ê·¸ëŒ€ë¡œ framesì— ë°˜ì˜í•˜ì„¸ìš”.\n"
            "**ë¹ˆ ë¬¸ìì—´/ë¹ˆ ë°°ì—´/ë¹ˆ ê°ì²´ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. ë¶ˆëª…/false ê°’ì˜ í‚¤ëŠ” ìƒëµí•˜ì„¸ìš”.**"
        )
        max_tok = 900
    else:
        # ë‹¤ì¤‘ ì‚¬ì§„: food_structured ì™„ì „ ì œì™¸
        prompt = (
            "ì•„ë˜ ì´ë¯¸ì§€ë¥¼ **ì¶”ì¸¡ ì—†ì´** ê´€ì°°í•´ JSONìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n"
            "- ë©”íƒ€í‘œí˜„(ì‚¬ì§„/ì´ë¯¸ì§€/ì´¬ì˜/ë¬¼ê±´ ë“±) ê¸ˆì§€, íŒŒì¼ëª…/ë‚ ì§œ ì–¸ê¸‰ ê¸ˆì§€\n"
            "- ì„±ë³„Â·ì¸ì›ìˆ˜ ì¶”ì • ê¸ˆì§€, ë¶ˆí™•ì‹¤í•˜ë©´ ìƒëµ\n"
            "- ê° ì‚¬ì§„ì— ëŒ€í•´ summary, elements, indoor_outdoor, time_hint, place_hint, space_relations, visible_text, flow, has_foodë§Œ ì¶œë ¥\n"
            "- ìŒì‹Â·ì¥ì†Œ ê³ ìœ ëª…ì‚¬ëŠ” ë³´ì¼ ë•Œë§Œ ê¸°ë¡\n"
            "- visible_textëŠ” ì‹¤ì œ ë³´ì´ëŠ” ê¸€ìë§Œ\n"
            "- **food_structuredëŠ” ì–´ëŠ ì‚¬ì§„ì—ì„œë„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”**\n\n"
            "JSON í˜•ì‹:\n"
            "{\n"
            "  \"frames\": [\n"
            "    {\n"
            "      \"index\": 1,\n"
            "      \"summary\": \"...\",\n"
            "      \"elements\": [\"...\"],\n"
            "      \"indoor_outdoor\": \"indoor|outdoor|unknown\",\n"
            "      \"time_hint\": \"ì˜¤ì „|ì •ì˜¤|ì˜¤í›„|ì €ë…|ë°¤|ë¶ˆëª…\",\n"
            "      \"place_hint\": \"ë³´ì´ë©´ í•œ ë‹¨ì–´\",\n"
            "      \"space_relations\": \"ìµœëŒ€ 20ì\",\n"
            "      \"visible_text\": \"ë³´ì´ëŠ” í…ìŠ¤íŠ¸(ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)\",\n"
            "      \"flow\": \"ì´ë™|ë¨¸ë¬´ë¦„|ë¶ˆëª…\",\n"
            "      \"has_food\": true|false\n"
            "    }\n"
            "  ],\n"
            "  \"global\": {\"dominant_time\": \"ì˜¤ì „|ì •ì˜¤|ì˜¤í›„|ì €ë…|ë°¤|ë¶ˆëª…\", \"movement\": \"ìˆìŒ|ì—†ìŒ|ë¶ˆëª…\"}\n"
            "}\n"
            "**ì¤‘ìš”**: ì…ë ¥ëœ ì´ë¯¸ì§€ ìˆœì„œëŠ” **ì´¬ì˜ì‹œê° ì˜¤ë¦„ì°¨ìˆœ**ì…ë‹ˆë‹¤. ê·¸ ìˆœì„œë¥¼ ê·¸ëŒ€ë¡œ framesì— ë°˜ì˜í•˜ì„¸ìš”.\n"
            "**ë¹ˆ ë¬¸ìì—´/ë¹ˆ ë°°ì—´/ë¹ˆ ê°ì²´ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. ë¶ˆëª…/false ê°’ì˜ í‚¤ëŠ” ìƒëµí•˜ì„¸ìš”.**"
        )
        max_tok = 800

    content = [{"type":"text","text": prompt}]
    for data_url in sorted_images:
        url = data_url if isinstance(data_url, str) and data_url.startswith("data:image") else f"data:image/jpeg;base64,{data_url}"
        detail = "high" if len(sorted_images) == 1 else "low"
        content.append({"type":"image_url","image_url":{"url": url, "detail": detail}})

    r = throttled_chat_completion(
        model=MODEL_VISION,
        temperature=0.0,
        max_tokens=max_tok,
        response_format={"type":"json_object"},
        messages=[
            {"role":"system","content": sys},
            {"role":"user","content": content}
        ]
    )

    # [ì¶”ê°€] Vision ë‹¨ê³„ ë‚´ì¥ content_filter ê°ì§€
    try:
        finish_reason = r.choices[0].finish_reason
    except Exception:
        finish_reason = None
    if finish_reason == "content_filter":
        return {"unsafe": True, "reason": "content_filter"}

    try:
        data = json.loads(r.choices[0].message.content or "{}")
        frames = data.get("frames") or []
        for i, f in enumerate(frames, 1):
            f["index"] = i
        for f in frames:
            f["summary"] = clean_inline(f.get("summary",""))
            f["elements"] = [clean_inline(x) for x in (f.get("elements") or []) if x]
        data["date_sequence"] = date_info_iso
        data["ordering_debug"] = ordering_debug
        data["sorted_images"] = sorted_images  # [ì¶”ê°€] multi-enrichìš©
        # --- ê¸€ë¡œë²Œ ìŒì‹ í›„ë³´ ìœµí•© ì¶”ê°€ ---
        data["food_fusion"] = fuse_food_candidates(data)
        return data
    except Exception as e:
        raw = r.choices[0].message.content if r and r.choices else ""
        if raw:
            snippet = raw[:2000]
            print("ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨: ì›ë¬¸ ìŠ¤ë‹ˆí« ->", snippet)
            print("ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨: ì›ë¬¸ repr ->", repr(snippet))
        print("ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        return None

# ---------------- 2) ì´ˆì•ˆ ----------------
def draft_diary(analysis: dict | None, tone: str, category_hint: str, text_model: str = MODEL_TEXT) -> str:
    """
    í•µì‹¬: ì„¤ëª…ë¬¸ì´ ì•„ë‹ˆë¼ 'ë§í•˜ë“¯' ì“°ê¸°. ì§§ê³  ê¸´ ë¬¸ì¥ ì„ê¸°.
    '30ëŒ€ ì¼ê¸° í†¤.
    """
    if not analysis:
        return ""
    frames = analysis.get("frames") or []
    global_info = analysis.get("global") or {}
    date_sequence = analysis.get("date_sequence") or []

    def _to_date(x):
        try: return datetime.fromisoformat(str(x)).date()
        except Exception: return None

    date_changes = []
    if len(date_sequence) > 1:
        for i in range(1, len(date_sequence)):
            a = _to_date(date_sequence[i-1]); b = _to_date(date_sequence[i])
            if a and b and a != b:
                days_diff = (b - a).days
                if days_diff >= 1:
                    date_changes.append({"position": i + 1, "days_diff": days_diff})

    date_context = ""
    if date_changes:
        date_context = "\n[ì‹œê°„ íë¦„ ì •ë³´]\n"
        for dc in date_changes:
            if dc["days_diff"] == 1: date_context += f"- {dc['position']}ë²ˆ ì‚¬ì§„ë¶€í„°: ë‹¤ìŒ ë‚ \n"
            elif dc["days_diff"] == 2: date_context += f"- {dc['position']}ë²ˆ ì‚¬ì§„ë¶€í„°: ì´í‹€ ë’¤\n"
            elif dc["days_diff"] == 3: date_context += f"- {dc['position']}ë²ˆ ì‚¬ì§„ë¶€í„°: ì‚¬í˜ ë’¤\n"
            else: date_context += f"- {dc['position']}ë²ˆ ì‚¬ì§„ë¶€í„°: {dc['days_diff']}ì¼ ë’¤\n"

    bullets = []
    for f in frames:
        idx = f.get("index"); s = f.get("summary",""); io = f.get("indoor_outdoor",""); tm = f.get("time_hint",""); ph = f.get("place_hint",""); flow= f.get("flow","")
        parts = []
        if s: parts.append(s)
        if io and io!="unknown": parts.append(f"({io})")
        if tm and tm!="ë¶ˆëª…": parts.append(f"[{tm}]")
        if ph: parts.append(f"#{ph}")
        if flow and flow!="ë¶ˆëª…": parts.append(f"{{{flow}}}")

        unknown_time_flags = any((f.get("time_hint") or "ë¶ˆëª…") == "ë¶ˆëª…" for f in frames)
        if unknown_time_flags:
            bullets.append("- [ê²½ê³ ] ì¼ë¶€ í”„ë ˆì„ time_hint=ë¶ˆëª…. ì´ í”„ë ˆì„ë“¤ì—ì„œëŠ” ì‹œê°„ë‹¨ì–´ë¥¼ ìƒì„±í•˜ì§€ ë§ˆë¼.")
        # ---------- ì—¬ê¸°ë¶€í„° ìŒì‹ í›„ë³´/ì¬ë£Œ ë‹¨ì„œ ì£¼ì… ----------
        fs = f.get("food_structured") or {}
        cands = (fs.get("main_dish_candidates") or [])
        top = cands[0] if cands else {}
        conf = float(top.get("confidence") or 0.0)
        name = (top.get("name") or "").strip()
        ings = ", ".join(fs.get("ingredients_visible") or [])
        vt = (f.get("visible_text") or "").strip()

        # ìŒì‹ í”„ë ˆì„ì´ë©´ ê¸€ì”¨ëŠ” ì¼ê¸° ë‹¨ì„œë¡œ ì“°ì§€ ì•Šê³ ,
        # ìŒì‹ëª…/ì¬ë£Œë§Œ ë‹¨ì„œë¡œ ì‚¬ìš©
        if f.get("has_food") is True:
            if name and conf >= 0.75:
                parts.append(f"#{name}")
            elif ings:
                parts.append(f"[ì¬ë£Œ:{ings}]")
        else:
            # ìŒì‹ì´ ì•„ë‹Œ í”„ë ˆì„ì—ì„œë§Œ visible_textë¥¼ íŒíŠ¸ë¡œ ì „ë‹¬
            if vt:
                parts.append(f"[í…ìŠ¤íŠ¸:{vt}]")
        # ---------- ìŒì‹ ë‹¨ì„œ ì£¼ì… ë ----------
        if parts: bullets.append(f"- {idx}ë²ˆ: " + " ".join(parts))

    dom_time = global_info.get("dominant_time","ë¶ˆëª…")
    movement = global_info.get("movement","ë¶ˆëª…")
    header = f"[íë¦„] ì‹œê°:{dom_time} ì´ë™:{movement}"
    length_rule = "5~7ë¬¸ì¥" if (category_hint == "journey_multi" or len(frames) > 1) else "3~4ë¬¸ì¥"

    sys = (
        "ë‹¹ì‹ ì€ 20~30ëŒ€ê°€ ì“°ëŠ” í•œêµ­ì–´ ì¼ê¸°ë¥¼ ì˜ ì“°ëŠ” ì‘ê°€ì…ë‹ˆë‹¤. "
        "ì„¤ëª…ë¬¸ì´ ì•„ë‹ˆë¼ 'ë§í•˜ë“¯' ì”ë‹ˆë‹¤. ìì—°ìŠ¤ëŸ¬ìš´ íšŒìƒì²´ë¡œ, ê³¼ì¥ ì—†ì´ ê°„ê²°í•˜ê²Œ."
        "ê°ê°ê³¼ ê°ì •ì€ ìµœì†Œí•œë§Œ ì”ë‹ˆë‹¤. ê³¼ì¥, ì˜ì„±ì–´, ë¹„ìœ  ê¸ˆì§€."
        "**ì…ë ¥ í”„ë ˆì„ ìˆœì„œë¥¼ ë°˜ë“œì‹œ ìœ ì§€**í•˜ê³ , ë‚ ì§œê°€ ë°”ë€ŒëŠ” ì§€ì ì—ì„œëŠ” ì „í™˜ì‚¬ë¥¼ ëª…ì‹œí•©ë‹ˆë‹¤."
    )
    user = f"""

ì•„ë˜ ê´€ì°° ë‹¨ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ 20~30ëŒ€ ìì—°ì²´ ì¼ê¸°ë¥¼ í•œ ë‹¨ë½ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

{header}
[ê´€ì°°]
{os.linesep.join(bullets) if bullets else "- ë‹¨ì„œ ì ìŒ"}
{date_context}

[ì¶œë°œ ê·œì¹™]

ê³¼ê±°í˜• ìœ ì§€. 1ì¸ì¹­ ì²´í—˜ì´ ë“œëŸ¬ë‚˜ë˜ 'ë‚˜ëŠ”' ìƒëµ.

ì²« ë¬¸ì¥ì€ 'í–‰ë™ 1ë¬¸ì¥'ìœ¼ë¡œ ì‹œì‘. ëŒ€ìƒ ë‚˜ì—´ ë˜ëŠ” ê´€ì°° ì„œìˆ  ê¸ˆì§€.

ì²« ë¬¸ì¥ì— ì‹œê°„ë‹¨ì„œ(time_hint: ì˜¤ì „/ì˜¤í›„/ì €ë…/ë°¤ ë“±)ì´ í¬í•¨ë˜ë©´ ì•ˆëœë‹¤.

ë‹¨ìˆœíˆ ì¥ë©´ì„ ë¬˜ì‚¬í•˜ì§€ ë§ê³ , ê²½í—˜ê³¼ í–‰ë™ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì¨ì£¼ì„¸ìš”.

ë¬¸ì¥ ìˆ˜: {length_rule}. ì§§ì€ ë¬¸ì¥ 1â€”2ê°œ í¬í•¨.

ì¤‘ìš”: ì‹œê°„ íë¦„ ì •ë³´ì— ë‚ ì§œ ë³€í™”ê°€ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´, í•´ë‹¹ ìœ„ì¹˜ì—ì„œ ë°˜ë“œì‹œ 'ë‹¤ìŒ ë‚ ', 'ì´í‹€ ë’¤', 'ì‚¬í˜ ë’¤', 'Nì¼ ë’¤' ë“±ìœ¼ë¡œ ë‚ ì§œ ì „í™˜ì„ í‘œì‹œ.

ë¬¸ì¥ ê°„ì—ëŠ” ë°˜ë“œì‹œ ì‹œê°„Â·ê³µê°„ ì—°ê²°ì–´ë¥¼ ë„£ëŠ”ë‹¤.

[ë¦¬ë“¬ ê·œì¹™ â€” ê°•ì œ]

ì—°ì† ë‹¨ë¬¸ ê¸ˆì§€: ë§ˆì¹¨í‘œ ê¸°ì¤€ 12ì ì´í•˜ ë¬¸ì¥ì´ 2íšŒ ì—°ì†ì´ë©´, ë‹¤ìŒ ë¬¸ì¥ì€ 25ì ì´ìƒ ë³µí•©ë¬¸ìœ¼ë¡œ ì“´ë‹¤.

ë³µí•©ë¬¸ ìµœì†Œ 2ê°œ: ì ‘ì†ì–´(ê·¸ë˜ì„œ/ë•Œë¬¸ì—/ë•ë¶„ì—/í•˜ì§€ë§Œ/ê·¸ë¦¬ê³ /ê·¸ëŸ¬ë‹¤ê°€ ë“±)ë‚˜ ê´€ê³„ì ˆ(â€¦í•œ â€¦)ì„ í¬í•¨í•œ 25ì ì´ìƒ ë¬¸ì¥ì„ ìµœì†Œ 2ê°œ í¬í•¨í•œë‹¤.

ë‹¨ë¬¸ ìµœì†Œ 2ê°œ: 6~12ì ì‚¬ì´ì˜ ì§§ì€ í–‰ë™ ë¬¸ì¥ì„ ìµœì†Œ 2ê°œ ì„ëŠ”ë‹¤.

ì‹œì‘Â·ì¤‘ê°„Â·ë§ˆì¹¨ ë³€ì£¼: ì‹œì‘ì€ í–‰ë™ ë‹¨ë¬¸, ì¤‘ê°„ì—ëŠ” ë³µí•©ë¬¸ ì¤‘ì‹¬, ë§ˆì¹¨ì€ ì§§ì€ ì •ë¦¬ ë¬¸ì¥ìœ¼ë¡œ ë¦¬ë“¬ì„ ë‹«ëŠ”ë‹¤.

ë™ì¼ ì¢…ê²°ì–´ 3íšŒ ì—°ì† ê¸ˆì§€: â€˜~í–ˆë‹¤.â€™ê°€ 3íšŒ ì—°ì†ì´ë©´ ì„¸ ë²ˆì§¸ ë¬¸ì¥ì€ ì´ìœ ì ˆì„ í¬í•¨í•œ ë³µí•©ë¬¸ìœ¼ë¡œ ë°”ê¾¼ë‹¤.

[ì‹œê°„í‘œí˜„ ê·œì¹™ â€” ê°•ì œ]

ì²« ë¬¸ì¥ì€ ì‹œê°„ë‹¨ì–´(ì˜¤ì „/ì •ì˜¤/ì˜¤í›„/ì €ë…/ë°¤)ë¡œ ì‹œì‘í•˜ë©´ ì•ˆ ëœë‹¤. ë¬¸ì¥ ì‹œì‘ì— ì‹œê°„ë‹¨ì–´ê°€ ì˜¤ë©´ ì „ì²´ ì‘ë‹µì´ ë¬´íš¨ë‹¤. í–‰ë™ìœ¼ë¡œ ì‹œì‘í•˜ë¼.

ì–´ë–¤ ë¬¸ì¥ì—ë„ time_hintê°€ 'ë¶ˆëª…'ì¸ í”„ë ˆì„ì—ì„œ ì‹œê°„ë‹¨ì–´ë¥¼ ë§Œë“¤ì§€ ë§ˆë¼.

time_hintê°€ ìˆì„ ë•Œë§Œ í•´ë‹¹ í”„ë ˆì„ ë¬¸ì¥ ì¤‘ê°„ì— ì§§ê²Œ ë„£ì„ ìˆ˜ ìˆë‹¤.

ì‹œì œëŠ” ì „ë¶€ ê³¼ê±°í˜•ìœ¼ë¡œ í†µì¼í•œë‹¤. ì§„í–‰í˜•Â·í˜„ì¬ ì™„ë£Œí˜• ê¸ˆì§€.'ë¨¹ìœ¼ë©°~í¼ì¡Œë‹¤' ê°™ì€ ì§„í–‰ + ê³¼ê±° í˜¼ìš©ì´ ë‚˜ì˜¤ë©´ ì¬ì‘ì„±í•œë‹¤.

ì—°ê²°ì–´ì— ì‹œê°„ì–´ê°€ í¬í•¨ë˜ì–´ë„ ë¬¸ì¥ ì²«ë¨¸ë¦¬ ì‹œê°„ì–´ ê¸ˆì§€ ê·œì¹™ì€ ìœ ì§€í•œë‹¤.

[ì ˆì œ ê·œì¹™]

ê¸ˆì§€êµ¬ : 'í…Œì´ë¸” ìœ„ì— ~ ì¤€ë¹„ë˜ì–´ ìˆì—ˆë‹¤", "ê°€ì§€ëŸ°íˆ ë†“ì¸ ëª¨ìŠµ", "ëˆˆì— ë“¤ì–´ì™”ë‹¤", "í–¥ì´ ~ì‹ìš•ì„ ìê·¹í–ˆë‹¤.", "ì¡°ìš©íˆ ì•‰ì•„", "í•œ ì… ë¨¹ê³  ë‚˜ë‹ˆ ë§ˆìŒì´ ~ì¡Œë‹¤","ìƒê°ì— ì ê²¼ë‹¤",

ìœ„ í‘œí˜„ë“¤ì€ ì˜ë¯¸ë¥¼ ë³´ì¡´í•´ í–‰ë™ìœ¼ë¡œ ì¹˜í™˜.

ê°ê° ì–¸ê¸‰ì€ ìµœëŒ€ 2ê°œ. ë¯¸ê°Â·í›„ê° ì¤‘ 1ê°œ + ì˜¨ë„Â·ì´‰ê° ì¤‘ 1ê°œë§Œ í—ˆìš©.

ê°ì • ë¬¸ì¥ ìµœëŒ€ 1ê°œ. 'ê¸°ë»¤ë‹¤/ì¦ê±°ì› ë‹¤/íŠ¹ë³„í–ˆë‹¤/ê´œíˆ' ë“± ì§ì ‘ ê°ì •ì–´ ê¸ˆì§€. í–‰ë™ìœ¼ë¡œ ì•”ì‹œ.

ì˜ì„±ì–´Â·ê³¼ì¥ í‘œí˜„ ê¸ˆì§€: ì§€ê¸€ì§€ê¸€/ë°”ì‚­/ì´‰ì´‰/ì…ì•ˆ ê°€ë“/ì½”ë/ìŠ¤ë©°ë“¤ë‹¤/ê°ëŒë‹¤/ê°„ì§ˆì´ë‹¤/í•œê»/ê°€ë“/ë²…ì°¨ë‹¤/íŠ¹ë³„í–ˆë‹¤/ë¯¸ì†Œê°€ ì§€ì–´ì¡Œë‹¤.

ë¹„ìœ  ê¸ˆì§€. ìˆ˜ì‹ì–´ëŠ” ì§§ê²Œ.


[ê²½í—˜ ì¤‘ì‹¬]

ë‹¨ìˆœíˆ ì¥ë©´ì„ ë¬˜ì‚¬í•˜ì§€ ë§ê³ , ê·¸ ìˆœê°„ì˜ ê²½í—˜ê³¼ í–‰ë™ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì¨ì£¼ì„¸ìš”.

'ë‚˜ëŠ”' ê°™ì€ ì£¼ì–´ë¥¼ ì§ì ‘ ì“°ì§€ ì•Šì•„ë„, ì£¼ì²´ì˜ í–‰ë™ì´ ìì—°ìŠ¤ëŸ½ê²Œ ë“œëŸ¬ë‚˜ì•¼ í•©ë‹ˆë‹¤.

ì‹œê°ì  ë¬˜ì‚¬ë§Œ ë‚˜ì—´í•˜ì§€ ë§ê³ , í›„ê°Â·ì‹ê°Â·ì´‰ê°Â·ì˜¨ë„ê°Â·ì§ˆê° ê°™ì€ ë³´ì¡° ê°ê°ì„ ì„ìœ¼ì„¸ìš”.

ê·¸ëŸ¬ë‚˜ ì£¼ìš” ê°ê°(ì²­ê°, ë¯¸ê°) í•œ ë‘ê°œë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ì•”ì‹œë¡œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

ê°ì •ì´ ë“œëŸ¬ë‚  ë•ŒëŠ” ì™œ ê·¸ëŸ° ê°ì •ì´ ìƒê²¼ëŠ”ì§€ êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ í•¨ê»˜ í‘œí˜„í•˜ì„¸ìš”.

ê·¸ë¦¬ê³  ê°ì •ì„ ê²°ê³¼ë¡œ ë‘ì§€ ë§ê³ , í–‰ìœ„ë‚˜ ì¹¨ë¬µìœ¼ë¡œ ì•”ì‹œë¥¼ í•˜ë„ë¡ í•©ë‹ˆë‹¤.

ë¬¸ì¥ ë¦¬ë“¬ì´ ë‹¨ì¡°ë¡œì›Œì§€ì§€ ì•Šë„ë¡ ì§§ì€ ë¬¸ì¥ê³¼ ë¬˜ì‚¬ ë¬¸ì¥ì„ êµì°¨í•´ ë³€ì£¼í•˜ì„¸ìš”.

í•œ ë‘ ë¬¸ì¥ì€ ì§§ê²Œ ëŠê³ , ì¤‘ê°„ì— í˜¸í¡ì„ ë§Œë“¤ì–´ ì¤˜ì•¼ í•©ë‹ˆë‹¤.

'í…Œì´ë¸”/ìŒì‹/í–¥'ê°™ì€ ë³´í¸ ëª…ì‚¬ëŠ” ê°€ëŠ¥í•œ í•œ í–‰ë™, ì‚¬ë¬¼ ìƒí˜¸ì‘ìš©ìœ¼ë¡œ ëŒ€ì²´.

ê´€ì°°ë™ì‚¬(ë³´ì˜€ë‹¤/ëˆˆì— ë“¤ì–´ì™”ë‹¤/ë³´ì˜€ë˜)ëŠ” ê¸ˆì§€. ë™ì¼ ì •ë³´ëŠ” 'ë¬´ì—‡ì„ í–ˆëŠ”ì§€'ë¡œ í‘œí˜„.

ê°ê°->ê°ì •ì˜ ì§§ì€ ì¸ê³¼ë¥¼ ê° ì „í™˜ë¶€ì— 1íšŒ ì´ìƒ ë„£ëŠ”ë‹¤.

ê°™ì€ íŒ¨í„´ ë°˜ë³µ ê¸ˆì§€.ì˜ˆë¥¼ ë“¤ì–´ ~í–ˆë‹¤, ~í–ˆë‹¤ê°€ 3íšŒ ì´ìƒ ì—°ì†ë˜ë©´ ë‹¤ìŒ ë¬¸ì¥ì€ ë³µí•©ë¬¸ìœ¼ë¡œ ì“´ë‹¤.


[ì‚¬ì‹¤ ì¼ì¹˜]

ìŒì‹Â·ì¥ì†Œ ê³ ìœ ëª…ì‚¬ëŠ” ë³´ì¼ ë•Œë§Œ ì‚¬ìš©.

ë³´ì´ì§€ ì•Šìœ¼ë©´ ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ëŒ€ì²´ ì´ë¦„ì„ ë§Œë“¤ì§€ ë§ ê²ƒ.

í•œì‹ ë°˜ì°¬ë¥˜ëŠ” 'ë°˜ì°¬', ë‹¨í’ˆ ìš”ë¦¬ëŠ” 'ìš”ë¦¬' ì •ë„ë¡œë§Œ í‘œí˜„.

ì‚¬ëŒì´ ë³´ì´ì§€ ì•Šìœ¼ë©´ êµ°ì¤‘ ë¬˜ì‚¬ ê¸ˆì§€. ì†Œë¦¬Â·ëƒ„ìƒˆ ìƒì„± ê¸ˆì§€.


[ìŒì‹ëª… ì‚¬ìš© ê·œì¹™]

ê° í”„ë ˆì„ì˜ food_structured.main_dish_candidatesì—ì„œ ìµœìƒìœ„ í›„ë³´ì˜ confidenceâ‰¥0.75ë©´ ê·¸ ìŒì‹ ì •ì‹ ëª…ì¹­ ì‚¬ìš© ê°€ëŠ¥

0.5â‰¤confidence<0.75ë©´ ëª…ì¹­ ëŒ€ì‹  ì¬ë£Œ ê¸°ë°˜ í‘œí˜„ë§Œ ì‚¬ìš©

confidence<0.5ë©´ ì¼ë°˜ì–´('ìš”ë¦¬','ë°˜ì°¬')ë§Œ ì‚¬ìš©.

visible_textì— ë©”ë‰´ëª…ì´ ì‹¤ì œë¡œ ë³´ì´ë©´ confidenceì™€ ë¬´ê´€í•˜ê²Œ ê·¸ í‘œê¸° ê·¸ëŒ€ë¡œ ì‚¬ìš©.


[ì‘ì„± ê·œì¹™ â€” 20~30ëŒ€ ìì—°ì²´]

ì²« ë¬¸ì¥ì€ ê³ ì •ë˜ì–´ìˆì§€ ì•Šë‹¤. ë§¥ë½ê³¼ ê°ê°ì„ ìˆœì„œë¡œ ë°°ì¹˜í•œë‹¤.

ê·¸ë¦¬ê³  ì²« ë¬¸ì¥ì€ ì ˆëŒ€ ê´€ì°°í•˜ëŠ” ë‚´ìš©ì´ ë“¤ì–´ê°€ë©´ ì•ˆëœë‹¤. ê²½í—˜ì— ëŒ€í•œ ë‚´ìš©ì´ ë“¤ì–´ê°€ì•¼ ëœë‹¤.

ì‹œê°ì  ë¬˜ì‚¬ë§Œ ë‚˜ì—´í•˜ì§€ ë§ê³ , í›„ê°Â·ì‹ê°Â·ì´‰ê°Â·ì˜¨ë„ê°Â·ì§ˆê° ê°™ì€ ë³´ì¡° ê°ê°ì„ ì„ìœ¼ì„¸ìš”.

ëª¨ë“  ë¬¸ì¥ì€ ê³¼ê±°í˜•ìœ¼ë¡œ í†µì¼. ì¤‘ìš”í•¨.

ì§ì ‘ ì²´í—˜ ì‹œì ìœ¼ë¡œ ì „í™˜í•˜ë¼. í–‰ë™ì´ ì„œìˆ ì ì´ì§€ ì•Šê³  ì²´í—˜ì ì´ê²Œ í•´ì•¼í•œë‹¤. í–‰ìœ„ ì¤‘ì‹¬ì˜ ë¬¸ì¥ê³¼ ê°ì •,ìƒê°ì„ ì„ë˜ ì ˆì œ.

ì¤‘ìš” "ë‚˜ëŠ”"ì´ë‚˜ "ì£¼ì–´"ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì“°ì§€ ì•Šê³ ë„, ì£¼ì²´ì˜ í–‰ìœ„ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë“œëŸ¬ë‚˜ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”.

ë§í•˜ë“¯ ì¨ë¼. ë³´ê³ /í•˜ê³ /ëŠë‚€ ê²ƒì„ ì§ì ‘ í–‰ìœ„ ì¤‘ì‹¬ ë¬¸ì¥ìœ¼ë¡œ ë°”ê¿”ê°€ë©° ì§§ê³  ê¸´ ë¬¸ì¥ ì„ì–´ í‘œí˜„.

'~ìˆì—ˆë‹¤'ë§Œ ë°˜ë³µí•˜ì§€ ë§ê³ , ë‹¤ì–‘í•œ í‘œí˜„ë“¤ë¡œë¡œ ë³€ì£¼í•˜ë¼.

ê°ì • ë³€í™”ì˜ ì›ì¸ì´ ìˆì–´ì•¼ í•œë‹¤.

ê°ì •ì€ ì§ì ‘ ë§í•˜ê¸°ë³´ë‹¤ 'ì¡°ê¸ˆ/ì ê¹/ê´œíˆ' ê°™ì€ ë¶€ì‚¬ë¡œ ì€ì€íˆ.

ìŒì‹ ì‚¬ì§„ì˜ ê°ê°ì€ êµ¬ì²´ì  ê°ê°ìœ¼ë¡œ ì•”ì‹œ. ê·¸ë¦¬ê³  ê°ì •ì€ ìˆìœ¼ë‚˜ ì›ì¸ê³¼ ì—°ê²°ë˜ì–´ì•¼ í•œë‹¤.

í•˜ì§€ë§Œ ì¶”ìƒì ì¸ ê°ê°ì€ ê¸ˆì§€. êµ¬ì²´ì ì¸ ê°ê°ìœ¼ë¡œ ì•”ì‹œ.

ë©”íƒ€í‘œí˜„(ì‚¬ì§„/ì´ë¯¸ì§€/ì´¬ì˜ ë“±) ê¸ˆì§€, íŒŒì¼ëª…/ë‚ ì§œ ê¸ˆì§€.

ì„±ë³„Â·ì¸ì›ìˆ˜ ì¶”ì • ê¸ˆì§€, ê´€ê³„/ê±°ë¦¬ê°ì€ ê°„ì ‘ì ìœ¼ë¡œ.

ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ ë¬¸ì¥ì˜ ë¦¬ë“¬ì„ ë‹¤ì–‘í•˜ê²Œ ì‚¬ìš©í•´ì•¼ í•¨. ì§§ì€ ë¬¸ì¥ê³¼ ë¬˜ì‚¬ ì¤‘ì‹¬ ë¬¸ì¥ì„ êµì°¨ì‹œì¼œì•¼ í•¨. ê°ì •ì˜ ê³ ì €ê°€ ëŠê»´ì ¸ì•¼ í•œë‹¤.

'~í•˜ë©° ~í¼ì¡Œë‹¤, ~í•˜ê³  ~ìŠ¤ì³¤ë‹¤'ì²˜ëŸ¼ ë™ì‹œì§„í–‰+ê²°ê³¼ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ì›ì¸ê³¼ ê²°ê³¼ë¥¼ ë¶„ë¦¬í•´ ê³¼ê±°í˜• ë‘ ë¬¸ì¥ìœ¼ë¡œ ì“´ë‹¤.

ë¬¸ì¥ ìˆ˜: {length_rule}. ì§§ì€ ë¬¸ì¥ 1â€”2ê°œ í¬í•¨. ê¸¸ì´ ë¶„í¬: 6~12ì ë‹¨ë¬¸â‰¥2, 25ì ì´ìƒ ë³µí•©ë¬¸â‰¥2.

í†¤: {tone or "ì¤‘ë¦½"} (ê³¼ì¥ ê¸ˆì§€, ë‹´ë°±í•˜ê²Œ).


[ìœ„ë°˜ ì‹œ ì¬ì‘ì„±]

ì¶œë ¥ì´ ì‹œê°„ë‹¨ì–´ë¡œ ì‹œì‘í•˜ê±°ë‚˜ ê´€ì°° ë‚˜ì—´ë¡œ ì‹œì‘í•˜ë©´ ì¦‰ì‹œ ì¬ì‘ì„±í•˜ë¼. ì²« ë¬¸ì¥ì€ í–‰ë™ì´ì–´ì•¼ í•œë‹¤.


[ì¶œë ¥ ì„œì‹ ê°•í™”]

í”„ë ˆì„ iì— ëŒ€ì‘í•˜ëŠ” ë¬¸ì¥ì€ ë°˜ë“œì‹œ <f{{i}}>ë¡œ ì‹œì‘í•´ </f{{i}}>ë¡œ ëëƒ…ë‹ˆë‹¤.

ê°™ì€ í”„ë ˆì„ì˜ ì—¬ëŸ¬ ë¬¸ì¥ì€ í•˜ë‚˜ì˜ íƒœê·¸ ì•ˆì— í¬í•¨í•´ë„ ë©ë‹ˆë‹¤.

íƒœê·¸ëŠ” ì¶œë ¥ì—ë§Œ ì“°ì´ë©° ìµœì¢… ê²°ê³¼ì—ì„œ ì œê±°ë©ë‹ˆë‹¤.

ê¸ˆì§€êµ¬ê°€ ìƒì„±ë  ê²½ìš° ê°™ì€ ì˜ë¯¸ë¥¼ 'í–‰ë™'ìœ¼ë¡œ ì¹˜í™˜í•´ ë‹¤ì‹œ ì‘ì„±.

ê°<f{{i}}>...</f{{1}}>ë¸”ë¡ì˜ ì²« ë¬¸ì¥ì€ í–‰ë™ìœ¼ë¡œ ì‹œì‘í•˜ê³ , ë‘ ë²ˆì§¸ ë¬¸ì¥ì—ì„œë§Œ ê°ê°Â·ê°ì •Â·ê²°ê³¼ë¥¼ ì—°ê²°í•œë‹¤.

ëª¨ë“  <f{{i}}>ë¸”ë¡ ì‚¬ì´ì—ëŠ” ì—°ê²°ì–´ 1ê°œ ì´ìƒì„ ë‘”ë‹¤.
"""
    r = throttled_chat_completion(
        model=text_model,
        temperature=0.20,
        top_p=0.9,
        max_tokens=600,
        messages=[
            {"role":"system","content": sys},
            {"role":"user","content": user}
        ]
    )
    draft = (r.choices[0].message.content or "").strip()

    draft = clean_inline(draft)
    draft = replace_proper_nouns_if_no_visible_text(analysis, draft)
    draft = simplify_food_enumeration(draft)  # í•„ìš” ì‹œ ì œê±° ë˜ëŠ” ì¡°ê±´ë¶€ ì‹¤í–‰
    draft = soften_report_tone(draft)

    # íƒœê·¸ ê¸°ë°˜ ì¬ë°°ì—´ ì‹œë„
    reordered = _reorder_by_tags(draft, n_frames=len(frames), date_sequence=date_sequence)
    if reordered:
        draft = reordered
    else:
        draft = _TAG_RE.sub("", draft)
    has_break = len(_day_break_positions(date_sequence)) > 0
    if has_break and not _TIME_SHIFT_PAT.search(draft):
        stitched = compose_from_frames(analysis)
        if stitched:
            draft = stitched
    return draft

# ----------- êµì°¨ê²€ì¦: ë™ì¼ í”„ë¡¬í¬íŠ¸, ë‹¤ë¥¸ ëª¨ë¸ -----------
def _norm(x: str) -> str:
    return re.sub(r"\s+", " ", (x or "").strip())

def select_draft_via_cross_validation(analysis: dict, tone: str, category_hint: str) -> tuple[str, dict]:
    primary = draft_diary(analysis, tone, category_hint, text_model=MODEL_TEXT)
    used = "primary"
    alt = None
    debug = {"primary_len": len(primary), "alt_len": 0, "used": used, "same": None, "primary_model": MODEL_TEXT, "alt_model": ALT_TEXT_MODEL}

    # ALTê°€ ê¸°ë³¸ê³¼ ë‹¤ë¥¼ ë•Œë§Œ ìˆ˜í–‰
    if ALT_TEXT_MODEL and ALT_TEXT_MODEL != MODEL_TEXT:
        try:
            alt = draft_diary(analysis, tone, category_hint, text_model=ALT_TEXT_MODEL)
            debug["alt_len"] = len(alt)
            if _norm(alt) == _norm(primary):
                debug["same"] = True
                used = "primary"
                return primary, debug
            else:
                debug["same"] = False
                used = "alt"
                debug["used"] = used
                return alt, debug
        except Exception as e:
            debug["alt_error"] = str(e)
            return primary, debug
    else:
        debug["note"] = "ALT_TEXT_MODEL is same as primary or unset"
        return primary, debug

# ---------------- 3) ë³´ì • ----------------
def refine_diary(analysis: dict | None, draft: str, tone: str, category_hint: str) -> str:
    if not draft:
        return ""
    frames = analysis.get("frames") or [] if analysis else []
    length_rule = "54ë¬¸ì¥"

    sys = "ë‹¹ì‹ ì€ ë§í•˜ë“¯ ì“°ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë‹¤ë“¬ëŠ” í•œêµ­ì–´ ì—ë””í„°ì…ë‹ˆë‹¤."
    user = f"""

[ì´ˆì•ˆ]
{draft}

[ë³´ì • ì§€ì¹¨]

1ì¸ì¹­ ì²´í—˜ì²´ + ê³¼ê±°í˜• ìœ ì§€. ê´€ì°° í‘œí˜„(ëˆˆì— ë“¤ì–´ì™”ë‹¤/ë³´ì˜€ë‹¤)ì€ í–‰ë™ í‘œí˜„(ì ì‹œ ë°”ë¼ë´¤ë‹¤/ì•ì— ìˆì—ˆë‹¤)ë¡œ ì •ë¦¬.

ì§ì ‘ ì²´í—˜ ì‹œì ìœ¼ë¡œ ì „í™˜í•˜ë¼. í–‰ë™ì´ ì„œìˆ ì ì´ì§€ ì•Šê³  ì²´í—˜ì ì´ê²Œ í•´ì•¼í•œë‹¤. í–‰ìœ„ ì¤‘ì‹¬ì˜ ë¬¸ì¥ê³¼ ê°ì •,ìƒê°ì„ ì„ë˜ ì ˆì œ.

ì¤‘ìš” "ë‚˜ëŠ”"ì´ë‚˜ "ì£¼ì–´"ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì“°ì§€ ì•Šê³ ë„, ì£¼ì²´ì˜ í–‰ìœ„ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë“œëŸ¬ë‚˜ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”.

ì¥ë©´ ê°„ì˜ ë§¥ë½ ì—°ê²°ì–´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ê°€í•´ ì‹œê°„ íë¦„ì„ ì•”ì‹œí•˜ë¼.

ê°ì •ì€ í•œìˆœê°„ì´ ì•„ë‹ˆë¼ ì‹œê°„ ì†ì—ì„œ ë³€í™”í•˜ëŠ” ëŠë‚Œìœ¼ë¡œ ì¡°ì •í•˜ë¼.

ìŒì‹ëª… ì‚¬ìš©ì€ ë¶„ì„ ë‹¨ê³„ì˜ ê¸°ì¤€ì„ ë”°ë¦„: visible_text ìˆê±°ë‚˜ top.confâ‰¥0.75ì¼ ë•Œë§Œ ëª…ì¹­, ì•„ë‹ˆë©´ ì¬ë£Œí‘œí˜„.

ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ê³ ìœ ëª…ì‚¬(ìš”ë¦¬ëª…Â·ì§€ëª…) ê¸ˆì§€. ë³´ì´ì§€ ì•Šìœ¼ë©´ ì¼ë°˜ì–´ ìœ ì§€.

ì‚¬ëŒì´ ë³´ì´ì§€ ì•Šìœ¼ë©´ êµ°ì¤‘ ë¬˜ì‚¬ ê¸ˆì§€. ì†Œë¦¬Â·ëƒ„ìƒˆ ìƒì„± ê¸ˆì§€.

ê°ì •ì„ êµ¬ì²´ ê°ê°ìœ¼ë¡œ ìì—°í™”. ë¦¬ë“¬ ë‹¨ì¡°ëŠ” ë¬¸ì¥ ê¸¸ì´ ë³€ì£¼ë¡œ ë³´ì •.

ê°ì • ë³€í™”ì˜ ì›ì¸ì´ ìˆì–´ì•¼ í•œë‹¤. ê°ì •ì˜ ì›ì¸ê³¼ ë§¥ë½ì´ ìˆì–´ì•¼ í•˜ë¯€ë¡œ ì§§ê²Œë¼ë„ ì´ìœ ,ìƒí™©ì„ ì œì‹œí•´ì•¼ í•œë‹¤.

ë„ˆë¬´ ë”±ë”±í•œ ëª…ì‚¬êµ¬ ì—°ì‡„, 'ì¼ìƒì ì¸ í’ê²½' ê°™ì€ ì¶”ìƒ í‘œí˜„ì€ êµ¬ì²´ë¡œ ì¹˜í™˜í•˜ê±°ë‚˜ ì œê±°.

ë¬¸ì¥ ê¸¸ì´ì™€ ì–´ë¯¸ë¥¼ ë‹¤ì–‘í™”. '~ìˆì—ˆë‹¤' ë°˜ë³µì„ ì¤„ì´ê³  ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ë©° ë³€í™”ì‹œí‚¤ê±°ë‚˜ í•„ìš”í•œ ê³³ë§Œ ë‚¨ê¹€.

ê°ì •ì˜ í¬í™”ê°€ ë˜ì§€ ì•Šë„ë¡ í•œ ìš”ì†Œë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ì•”ì‹œë¡œ ì²˜ë¦¬í•´ë¼.

ê°ê°ì  ë¬˜ì‚¬ê°€ ì¼ì •í•œ íŒ¨í„´ìœ¼ë¡œ ë‚˜ì˜¤ì§€ ì•Šê²Œ ë¦¬ë“¬ì„ ì¡°ì •í•˜ê³  ë¬¸ì¥ í˜¸í¡ì„ ë‹¤ë¥´ê²Œ êµ¬ì„±í•˜ë¼.

ê³¼ì¥/ë¹„ìœ /ë©”íƒ€í‘œí˜„ ê¸ˆì§€ ìœ ì§€. í•œ ë‹¨ë½ ìœ ì§€.

ê¸ˆì§€êµ¬ ë°œê²¬ ì‹œ ë°˜ë“œì‹œ ê°™ì€ ì˜ë¯¸ë¥¼ 'í–‰ë™'ìœ¼ë¡œ ì¹˜í™˜í•´ ë‹¤ì‹œ ì‘ì„±.

ê° ë¬¸ì¥ì— ëŒ€í•´ "ì›ì¸->ê²°ê³¼"ê°€ ë“œëŸ¬ë‚˜ëŠ”ì§€ ì ê²€í•˜ê³ , ëˆ„ë½ ì‹œ ë•ë¶„ì—/ê·¸ë˜ì„œ/ë•Œë¬¸ì—ë¥¼ ì´ìš©í•´ í•œ ë¬¸ì¥ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì¬ë°°ì¹˜í•œë‹¤.

ë¬¸ë‹¨ ì „ì²´ì— í•˜ë‚˜ì˜ ë¯¸ì„¸í•œ ê°ì • ë³€í™”ë¥¼ ê¹”ê³ , ì²«Â·ì¤‘ê°„Â·ë§ˆì¹¨ ë¬¸ì¥ì— ê·¸ ë³€í™”ê°€ ì´ì–´ì§€ë„ë¡ ì ‘ì†ë¶€ë¥¼ ë³´ì •í•œë‹¤.

í˜„ì¬í˜•Â·ì§„í–‰í˜• ë°œê²¬ ì‹œ ì „ë¶€ ê³¼ê±°í˜•ìœ¼ë¡œ í†µì¼í•œë‹¤. í˜¼ìš©ì´ ë³´ì´ë©´ í•´ë‹¹ ë¬¸ì¥ ë¬¶ìŒì„ ë‘ ë¬¸ì¥ ê³¼ê±°í˜•ìœ¼ë¡œ ë¶„í•´í•œë‹¤.

ë¬¸ì¥ ìˆ˜: {length_rule}. í†¤: {tone or "ì¤‘ë¦½"}.ì¤‘ìš”.

'[ê²½ê³ ]' í‘œì‹œê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì œì•½ì„ ì ˆëŒ€ ìœ„ë°˜í•˜ì§€ ë§ˆë¼.


[ê°•ì œ ë³´ì • â€” ì‹œê°„Â·ì—°ê²°ì–´]

ë¬¸ì¥ ì‹œì‘ì˜ ì‹œê°„ë‹¨ì–´(ì˜¤ì „/ì •ì˜¤/ì˜¤í›„/ì €ë…/ë°¤)ë¥¼ ì œê±°í•˜ê³  í–‰ë™ìœ¼ë¡œ ì¹˜í™˜í•˜ë¼.

time_hintê°€ 'ë¶ˆëª…'ì¸ í”„ë ˆì„ì—ì„œ ìƒì„±ëœ ì‹œê°„ë‹¨ì–´ë¥¼ ëª¨ë‘ ì‚­ì œí•˜ë¼.

í–‰ë™ê³¼ ê°ì • ì‚¬ì´ì— ë§¥ë½ì— ë§ëŠ” ì—°ê²°ì–´ë¥¼ ì‚¬ìš©í•˜ë¼. ë§¥ë½ì´ ì–´ìƒ‰í•˜ë©´ ì•ˆëœë‹¤.

ê°ì •ì€ í•œ ë¬¸ì¥, ë™ì‚¬/ë¶€ì‚¬ ê¸°ë°˜ì˜ ì•½í•œ í‘œí˜„ë§Œ ìœ ì§€í•˜ë¼.

í”„ë ˆì„ ì „í™˜ë§ˆë‹¤ ê·¸ í›„/ì ì‹œ ë’¤/ì´ì–´/ë‹¤ì‹œ/ê³³ì„ ì˜®ê²¨ ì¤‘ 1ê°œ ì´ìƒì„ ì‚½ì…í•œë‹¤. ëˆ„ë½ ì‹œ ìë™ ì‚½ì…í•˜ê³  ë¦¬ë“¬ì„ í•´ì¹˜ë©´ ìœ„ì¹˜ë¥¼ ì¡°ì •í•œë‹¤.

[ê°•ì œ ë³´ì • â€” ë¦¬ë“¬]

12ì ì´í•˜ ë‹¨ë¬¸ì´ 2íšŒ ì—°ì†ì´ë©´, ì´ì–´ì§€ëŠ” ë¬¸ì¥ì„ 25ì ì´ìƒ ë³µí•©ë¬¸ìœ¼ë¡œ ì¬ì‘ì„±í•œë‹¤.

ì ‘ì†ì–´ê°€ ë“¤ì–´ê°„ 25ì ì´ìƒ ë¬¸ì¥ì„ ìµœì†Œ 2ê°œ ìœ ì§€í•œë‹¤(ê·¸ë˜ì„œ/ë•Œë¬¸ì—/ë•ë¶„ì—/í•˜ì§€ë§Œ/ê·¸ë¦¬ê³ /ê·¸ëŸ¬ë‹¤ê°€ ë“±).

ë™ì¼ ì–´ë¯¸ ë°˜ë³µ ì œì–´: '~í–ˆë‹¤.' 3íšŒ ì—°ì† ê¸ˆì§€. ì„¸ ë²ˆì§¸ëŠ” ì´ìœ Â·ì¡°ê±´Â·ëŒ€ì¡° ì ‘ì†ì„ í¬í•¨í•´ ë³€í˜•í•œë‹¤.

ë¬¸ë‹¨ ì¢…ë£ŒëŠ” 10~16ì ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•œë‹¤.

[ì ˆì œ ì ìš©]

'[ê²½ê³ ]' í‘œì‹œê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì œì•½ì„ ì ˆëŒ€ ìœ„ë°˜í•˜ì§€ ë§ˆë¼.

ê°ê° ì–¸ê¸‰ ì´ 2ê°œ ì´ˆê³¼ ì‹œ ì´ˆê³¼ë¶„ ì‚­ì œ.

ê°ì • ì§ì ‘ í‘œí˜„ì€ 1ë¬¸ì¥ ì´í•˜. ë‚˜ë¨¸ì§€ëŠ” í–‰ë™ìœ¼ë¡œ ì•”ì‹œ.

ê´€ì°° ì¤‘ì‹¬ì´ ì•„ë‹Œ ì‹¤ì œ ê°ì •ì˜ ì›ì¸ì¸ê³¼ ë§¥ë½ì´ ìˆì–´ì•¼í•œë‹¤. ë”°ë¼ì„œ ê°ì •ì˜ ë³€í™”ê°€ ëŠê»´ì ¸ì•¼ í•œë‹¤.

ê¸ˆì§€ì–´ ì œê±°: ì§€ê¸€ì§€ê¸€, ë…¸ë¦‡ë…¸ë¦‡, ë°”ì‚­, ì´‰ì´‰, ì…ì•ˆ ê°€ë“, ì½”ë, ìŠ¤ë©°ë“¤ë‹¤, ê°ëŒë‹¤, ê°„ì§ˆì´ë‹¤, í•œê», ê°€ë“, ë²…ì°¨ë‹¤, íŠ¹ë³„í–ˆë‹¤, ë¯¸ì†Œê°€ ì§€ì–´ì¡Œë‹¤.

ë¹„ìœ Â·ìˆ˜ì‚¬ ì œê±°. ì¶”ìƒì–´('ì¼ìƒì ì¸ í’ê²½/íŠ¹ë³„í•œ ì‹œê°„')ëŠ” êµ¬ì²´ë¡œ ì¹˜í™˜í•˜ê±°ë‚˜ ì‚­ì œ.

ë³´ì´ì§€ ì•Šìœ¼ë©´ ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ëŒ€ì²´ ì´ë¦„ì„ ë§Œë“¤ì§€ ë§ ê²ƒ.

íŒ¨í„´ ì¤‘ë³µ ì œì–´:~í–ˆë‹¤.ê°€ 3íšŒ ì—°ì†ì´ë©´ ë„¤ ë²ˆì§¸ ë¬¸ì¥ì€ ì´ìœ ì ˆ í¬í•¨ ë³µí•©ë¬¸ìœ¼ë¡œ ì¬ì‘ì„±í•œë‹¤.


[ì¶œë ¥]

í•œ ë‹¨ë½ë§Œ. ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ì¶•ì†Œ. ê´€ì°° ë‚˜ì—´ ê¸ˆì§€.
"""
    r = throttled_chat_completion(
        model=MODEL_TEXT,
        temperature=0.15,
        max_tokens=700,
        messages=[
            {"role":"system","content": sys},
            {"role":"user","content": user}
        ]
    )
    final_text = (r.choices[0].message.content or "").strip()
    final_text = clean_inline(final_text)
    final_text = soften_report_tone(final_text)
    return final_text

# ê¸ˆì§€êµ¬ í™•ì¥
TRIM_PHRASES = [
    "ì¼ìƒì ì¸ ë¶„ìœ„ê¸°ë¡œ ê°€ë“ ì°¨ ìˆì—ˆë‹¤",
    "ì‹œê°ì ìœ¼ë¡œë„ ì¦ê±°ì›€ì„ ì£¼ì—ˆë‹¤",
    "ìƒì—…ì ì¸ ëŠë‚Œì„ ë”í–ˆë‹¤",
    "ê°€ì§€ëŸ°íˆ ë†“ì¸ ëª¨ìŠµì´",
    "ì‹ìš•ì„ ìê·¹",
    "í¸ì•ˆí•¨ì„ ê°€ì ¸ë‹¤ì£¼ì—ˆë‹¤",
    "ê¸€ìê°€ ëˆˆì— ë„ì—ˆë‹¤.",
    "ì†ë„ê°€ ëŠë ¤ì¡Œë‹¤",
]

# íŒ¨í„´ ì¹˜í™˜ ì¶”ê°€
REPORT_PATTERNS = [
    (r"í…Œì´ë¸” ìœ„ì— [^\.]+ ì¤€ë¹„ë˜ì–´ ìˆì—ˆë‹¤", "ì•ìœ¼ë¡œ ë‹¹ê²¨ ë†“ê³  ìë¦¬ë¥¼ ì •ë¦¬í–ˆë‹¤"),
    (r"ëˆˆì— ë“¤ì–´ì™”ë‹¤", "ì•ìœ¼ë¡œ ë‹¹ê²¨ ì‚´íˆë‹¤"),
    (r"í–¥ì´ [^\.]+ ìê·¹[^\.]*", "ê·¸ë¦‡ ê°€ê¹Œì´ì—ì„œ ê¹€ì´ ì˜¬ëë‹¤"),
    (r"í•œ ì… ë¨¹ê³  ë‚˜ë‹ˆ [^\.]+", "í•œ ì… ë¨¹ê³  ì†ë„ê°€ ëŠë ¤ì¡Œë‹¤"),
]
def soften_report_tone(text: str) -> str:
    if not text:
        return text
    t = text
    for p in TRIM_PHRASES:
        t = t.replace(p, "")
    for pat, rep in REPORT_PATTERNS:
        t = re.sub(pat, rep, t)
    t = re.sub(r"(ìˆì—ˆë‹¤\.)\s+(ìˆì—ˆë‹¤\.)", r"\1 ", t)
    return t.strip()

# ---------------- ì´ë¯¸ì§€ ì—†ì„ ë•Œ(ìš”ì•½ ë‹¨ì„œ) ----------------
def generate_from_lines(lines: list[str], tone: str) -> str:
    cat = decide_category_from_lines(lines)
    sys = "ë‹¹ì‹ ì€ 20~30ëŒ€ê°€ ì“°ëŠ” í•œêµ­ì–´ ì¼ê¸°ë¥¼ ì˜ ì“°ëŠ” ì‘ê°€ì…ë‹ˆë‹¤."
    user = f"""
[ê´€ì°° ë‹¨ì„œ]
{os.linesep.join(f"- {clean_inline(x)}" for x in lines)}

[ì‘ì„± ê·œì¹™ â€“ 20~30ëŒ€ ìì—°ì²´]

ë§í•˜ë“¯ ì¨ë¼. ì§§ê³  ê¸´ ë¬¸ì¥ ì„ê¸°.

ì‹œì œëŠ” ëª¨ë‘ ê³¼ê±°í˜•ìœ¼ë¡œ í†µì¼.

í–‰ë™+ê°ê° ì¤‘ì‹¬. ê³¼ì¥ ê¸ˆì§€.

ë©”íƒ€í‘œí˜„Â·ë‚ ì§œÂ·íŒŒì¼ëª… ê¸ˆì§€. ì„±ë³„/ì¸ì›ìˆ˜ ì¶”ì • ê¸ˆì§€.

54ë¬¸ì¥ ì¤€ìˆ˜.

í†¤: {tone or "ì¤‘ë¦½"}.

í•œ ë‹¨ë½ë§Œ ì¶œë ¥.
"""
    r = throttled_chat_completion(
        model=MODEL_TEXT,
        temperature=0.35,
        max_tokens=600,
        messages=[
            {"role":"system","content": sys},
            {"role":"user","content": user}
        ]
    )
    text = (r.choices[0].message.content or "").strip()
    text = soften_report_tone(clean_inline(text))
    return text

# ---------------- Fallback ----------------
FALLBACKS = [
    "ì˜¤ëŠ˜ì€ ë³„ì¼ ì—†ì—ˆì§€ë§Œ, ì‘ì€ ì¥ë©´ë“¤ì´ ê¸°ì–µì— ë‚¨ì•˜ë‹¤.",
    "ì§§ê²Œ ì›€ì§ì˜€ì„ ë¿ì¸ë° ê³µê¸°ê°€ ì¡°ê¸ˆ ë‹¬ëë‹¤.",
    "ë³„ìŠ¤ëŸ¬ìš´ ê±´ ì—†ì—ˆì§€ë§Œ, ì†ëì— ë‚¨ì€ ì´‰ê°ì´ ì˜¤ë˜ ê°”ë‹¤.",
]

# ---------------- HTML ----------------
@app.get("/")
def index():
    return render_template("SnaplogMain.html")

@app.get("/login")
def login_page():
    return render_template("login.html")

@app.get("/signup")
def signup_page():
    return render_template("signup.html")

@app.get("/alldiaries")
def all_diaries():
    return render_template("Snaplog_allDiaries.html")

@app.get("/map")
def map_page():
    return render_template("SnaplogMap.html")
    
@app.route('/mypage')
def mypage():
    return render_template("Snaplog_mypage.html")

@app.route('/reset-password')
def reset_password_page():
    """ë¹„ë°€ë²ˆí˜¸ ì¬ì„¤ì • í˜ì´ì§€"""
    return render_template('reset-password.html')


@app.post("/api/send-verification")
def api_send_verification():
    """íšŒì›ê°€ì… ì¸ì¦ ì½”ë“œ ì „ì†¡"""
    try:
        data = request.get_json(silent=True) or {}
        email = (data.get("email") or "").strip()
        
        if not email:
            return jsonify({
                'ok': False,
                'error': 'missing_email',
                'message': 'ì´ë©”ì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
            }), 400
        
        # ì´ë©”ì¼ í˜•ì‹ ê²€ì¦
        import re
        if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', email):
            return jsonify({
                'ok': False,
                'error': 'invalid_email',
                'message': 'ì˜¬ë°”ë¥¸ ì´ë©”ì¼ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.'
            }), 400
        
        # ì¸ì¦ ì½”ë“œ ìƒì„±
        code = generate_verification_code()
        
        # CosmosDBì— ì €ì¥
        save_result = save_verification_code(email, code, purpose="signup")
        if not save_result['ok']:
            return jsonify(save_result), 500
        
        # ì´ë©”ì¼ ë°œì†¡
        email_sent = send_verification_email(email, code)
        
        if email_sent:
            return jsonify({
                'ok': True,
                'message': 'ì¸ì¦ ì½”ë“œê°€ ì´ë©”ì¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.'
            }), 200
        else:
            return jsonify({
                'ok': False,
                'error': 'email_send_failed',
                'message': 'ì´ë©”ì¼ ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì´ë©”ì¼ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.'
            }), 500
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500


@app.post("/api/verify-code")
def api_verify_code():
    """ì¸ì¦ ì½”ë“œ í™•ì¸"""
    try:
        data = request.get_json(silent=True) or {}
        email = (data.get("email") or "").strip()
        code = (data.get("code") or "").strip()
        
        if not email or not code:
            return jsonify({
                'ok': False,
                'error': 'missing_fields',
                'message': 'ì´ë©”ì¼ê³¼ ì¸ì¦ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
            }), 400
        
        result = verify_code(email, code, purpose="signup")
        
        if result['ok']:
            return jsonify(result), 200
        else:
            status_code = 400 if result.get('error') in ['code_expired', 'wrong_code'] else 500
            return jsonify(result), status_code
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500


# ============ ë¹„ë°€ë²ˆí˜¸ ì¬ì„¤ì • API ============

@app.post("/api/forgot-password")
def api_forgot_password():
    """ë¹„ë°€ë²ˆí˜¸ ì°¾ê¸° (ì¬ì„¤ì • ë§í¬ ì „ì†¡)"""
    try:
        data = request.get_json(silent=True) or {}
        email = (data.get("email") or "").strip()
        
        if not email:
            return jsonify({
                'ok': False,
                'error': 'missing_email',
                'message': 'ì´ë©”ì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
            }), 400
        
        # ì‚¬ìš©ì ì¡´ì¬ í™•ì¸
        from auth_cosmos import users_container
        users = list(users_container.query_items(
            query="SELECT * FROM c WHERE c.email = @email",
            parameters=[{"name": "@email", "value": email}],
            enable_cross_partition_query=True
        ))
        
        if not users:
            # ë³´ì•ˆ: ì‚¬ìš©ìê°€ ì—†ì–´ë„ ì„±ê³µ ë©”ì‹œì§€ (ì´ë©”ì¼ ë…¸ì¶œ ë°©ì§€)
            return jsonify({
                'ok': True,
                'message': 'ì¬ì„¤ì • ë§í¬ê°€ ì´ë©”ì¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.'
            }), 200
        
        # ì¬ì„¤ì • í† í° ìƒì„±
        reset_token = generate_reset_token()
        
        # CosmosDBì— ì €ì¥
        save_result = save_reset_token(email, reset_token)
        if not save_result['ok']:
            return jsonify(save_result), 500
        
        # ì´ë©”ì¼ ë°œì†¡
        email_sent = send_password_reset_email(email, reset_token)
        
        if email_sent:
            return jsonify({
                'ok': True,
                'message': 'ì¬ì„¤ì • ë§í¬ê°€ ì´ë©”ì¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.'
            }), 200
        else:
            return jsonify({
                'ok': False,
                'error': 'email_send_failed',
                'message': 'ì´ë©”ì¼ ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
            }), 500
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500


@app.post("/api/reset-password")
def api_reset_password():
    """ë¹„ë°€ë²ˆí˜¸ ì¬ì„¤ì •"""
    try:
        data = request.get_json(silent=True) or {}
        token = (data.get("token") or "").strip()
        new_password = (data.get("new_password") or "").strip()
        
        if not token or not new_password:
            return jsonify({
                'ok': False,
                'error': 'missing_fields',
                'message': 'í† í°ê³¼ ìƒˆ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
            }), 400
        
        if len(new_password) < 6:
            return jsonify({
                'ok': False,
                'error': 'password_too_short',
                'message': 'ë¹„ë°€ë²ˆí˜¸ëŠ” ìµœì†Œ 6ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.'
            }), 400
        
        result = reset_password_with_token(token, new_password)
        
        if result['ok']:
            return jsonify(result), 200
        else:
            status_code = 400 if result.get('error') in ['token_expired', 'token_not_found'] else 500
            return jsonify(result), status_code
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500

# ============ ë§ˆì´í˜ì´ì§€ API ============

# ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
@app.get("/api/user/me")
@login_required
def api_get_user_info():
    """í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ"""
    try:
        user_info = get_user_by_id(request.user_id)
        
        if not user_info:
            return jsonify({
                'ok': False,
                'error': 'user_not_found',
                'message': 'ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }), 404
        
        return jsonify({
            'ok': True,
            'user': user_info
        }), 200
        
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500


# ë¹„ë°€ë²ˆí˜¸ ë³€ê²½
@app.post("/api/user/change-password")
@login_required
def api_change_password():
    """ë¹„ë°€ë²ˆí˜¸ ë³€ê²½"""
    try:
        data = request.get_json(silent=True) or {}
        
        current_password = data.get('current_password')
        new_password = data.get('new_password')
        
        if not current_password or not new_password:
            return jsonify({
                'ok': False,
                'error': 'missing_fields',
                'message': 'í˜„ì¬ ë¹„ë°€ë²ˆí˜¸ì™€ ìƒˆ ë¹„ë°€ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.'
            }), 400
        
        if len(new_password) < 6:
            return jsonify({
                'ok': False,
                'error': 'password_too_short',
                'message': 'ìƒˆ ë¹„ë°€ë²ˆí˜¸ëŠ” ìµœì†Œ 6ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.'
            }), 400
        
        result = change_password(request.user_id, current_password, new_password)
        
        if result['ok']:
            return jsonify(result), 200
        else:
            return jsonify(result), 400
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500


# íšŒì› íƒˆí‡´
@app.delete("/api/user/delete-account")
@login_required
def api_delete_account():
    """íšŒì› íƒˆí‡´"""
    try:
        data = request.get_json(silent=True) or {}
        
        password = data.get('password')
        
        if not password:
            return jsonify({
                'ok': False,
                'error': 'missing_password',
                'message': 'ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
            }), 400
        
        result = delete_user_account(request.user_id, password)
        
        if result['ok']:
            return jsonify(result), 200
        else:
            return jsonify(result), 400
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500
# ========================================
# ìƒˆë¡œìš´ ì¸ì¦ ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸
# ========================================

@app.post("/api/signup")
def api_signup():
    """íšŒì›ê°€ì… API"""
    try:
        data = request.get_json(silent=True) or {}
        email = (data.get("email") or "").strip()
        password = (data.get("password") or "").strip()
        name = (data.get("name") or "").strip()
        
        # ì…ë ¥ ê²€ì¦
        if not email or not password:
            return jsonify({
                'ok': False,
                'error': 'missing_fields',
                'message': 'ì´ë©”ì¼ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
            }), 400
        
        # ì´ë©”ì¼ í˜•ì‹ ê²€ì¦
        if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', email):
            return jsonify({
                'ok': False,
                'error': 'invalid_email',
                'message': 'ì˜¬ë°”ë¥¸ ì´ë©”ì¼ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.'
            }), 400
        
        # ë¹„ë°€ë²ˆí˜¸ ê¸¸ì´ ê²€ì¦
        if len(password) < 6:
            return jsonify({
                'ok': False,
                'error': 'weak_password',
                'message': 'ë¹„ë°€ë²ˆí˜¸ëŠ” ìµœì†Œ 6ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.'
            }), 400
        
        # ì‚¬ìš©ì ìƒì„±
        result = create_user(email, password, name)
        
        if result['ok']:
            return jsonify(result), 201
        else:
            status_code = 409 if result.get('error') == 'email_exists' else 500
            return jsonify(result), status_code
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500


@app.post("/api/login")
def api_login():
    """ë¡œê·¸ì¸ API"""
    try:
        data = request.get_json(silent=True) or {}
        email = (data.get("email") or "").strip()
        password = (data.get("password") or "").strip()
        
        # ì…ë ¥ ê²€ì¦
        if not email or not password:
            return jsonify({
                'ok': False,
                'error': 'missing_fields',
                'message': 'ì´ë©”ì¼ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
            }), 400
        
        # ì¸ì¦
        result = authenticate_user(email, password)
        
        if result['ok']:
            return jsonify(result), 200
        else:
            status_code = 404 if result.get('error') == 'user_not_found' else 401
            return jsonify(result), status_code
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500


@app.post("/api/logout")
@login_required
def api_logout():
    """ë¡œê·¸ì•„ì›ƒ API"""
    return jsonify({
        'ok': True,
        'message': 'ë¡œê·¸ì•„ì›ƒë˜ì—ˆìŠµë‹ˆë‹¤.'
    }), 200


@app.get("/api/me")
@login_required
def api_get_me():
    """í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ"""
    try:
        user = get_user_by_id(request.user_id)
        
        if user:
            return jsonify({
                'ok': True,
                'user': user
            }), 200
        else:
            return jsonify({
                'ok': False,
                'error': 'user_not_found',
                'message': 'ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }), 404
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500


@app.get("/api/diaries")
@login_required
def api_get_diaries():
    """ë‚´ ì¼ê¸° ëª©ë¡ ì¡°íšŒ"""
    try:
        limit = int(request.args.get('limit', 50))
        diaries = get_user_diaries(request.user_id, limit=limit)
        
        return jsonify({
            'ok': True,
            'diaries': diaries,
            'count': len(diaries)
        }), 200
        
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500

@app.post("/api/diaries")
@login_required
def api_save_diary():
    """ì¼ê¸° ì €ì¥ API"""
    try:
        data = request.get_json(silent=True) or {}
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        diary_text = data.get("text") or data.get("body") or ""
        if not diary_text.strip():
            return jsonify({
                'ok': False,
                'error': 'missing_text',
                'message': 'ì¼ê¸° ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
            }), 400
        
        # ì¼ê¸° ë°ì´í„° ì¶”ì¶œ
        title = data.get("title", "ì œëª© ì—†ìŒ")[:20]
        photos = data.get("photos", [])
        photo_items = data.get("photoItems", [])
        rep_index = data.get("repIndex", 0)
        diary_date = data.get("date", "")
        
        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            'category': data.get('category', ''),
            'tone': data.get('tone', 'ì¤‘ë¦½'),
            'repIndex': rep_index,
            'ts': data.get('ts'),
            'tn': data.get('tn')
        }
        
        # CosmosDBì— ì €ì¥
        result = save_diary(
            user_id=request.user_id,
            diary_text=diary_text,
            title=title,
            diary_date=diary_date,
            images=photos,
            photo_items=photo_items,
            metadata=metadata
        )
        
        if result['ok']:
            return jsonify(result), 201
        else:
            return jsonify(result), 500
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500

@app.get("/api/diaries/<diary_id>")
@login_required
def api_get_diary(diary_id):
    """íŠ¹ì • ì¼ê¸° ì¡°íšŒ"""
    try:
        diary = get_diary_by_id(diary_id, request.user_id)
        
        if diary:
            return jsonify({
                'ok': True,
                'diary': diary
            }), 200
        else:
            return jsonify({
                'ok': False,
                'error': 'not_found',
                'message': 'ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }), 404
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500


@app.delete("/api/diaries/<diary_id>")
@login_required
def api_delete_diary(diary_id):
    """ì¼ê¸° ì‚­ì œ"""
    try:
        result = delete_diary(diary_id, request.user_id)
        
        if result['ok']:
            return jsonify(result), 200
        else:
            status_code = 404 if result.get('error') == 'not_found' else 500
            return jsonify(result), status_code
            
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'ok': False,
            'error': 'server_error',
            'message': str(e)
        }), 500



# ---------------- API ----------------
@app.post("/api/auto-diary")
@login_required 
def api_auto_dairy():
    try:
        # 1) multipart/form-data
        if len(request.files) > 0:
            tone = request.form.get("tone") or "ì¤‘ë¦½"
            target_date = (request.form.get("targetDate") or "").strip()  # [ì¶”ê°€]
            photos = json.loads(request.form.get("photosSummary") or "[]")
            files = request.files.getlist("images")

            # Stage1 íˆ¬ì… ì´ë¯¸ì§€ ìˆ˜ ì»· (ì¶”ê°€)
            files = files[:min(len(files), STAGE1_TOP_N, MAX_IMAGES)]

            images = []
            saved_files = []
            debug_injected = []
            debug_meta_head = []

            print(f"\n{'='*60}")
            print(f"[multipart ì—…ë¡œë“œ] {len(files)}ê°œ íŒŒì¼ ìˆ˜ì‹ ")
            print(f"{'='*60}")

            for idx, f in enumerate(files[:MAX_IMAGES]):
                raw = f.read()
                orig_name = secure_filename(f.filename or f"upload_{uuid.uuid4().hex}")
                _, ext = os.path.splitext(orig_name)
                if not ext:
                    mime = (f.mimetype or "").lower()
                    ext = {
                        "image/jpeg": ".jpg",
                        "image/jpg": ".jpg",
                        "image/png": ".png",
                        "image/webp": ".webp",
                        "image/heic": ".heic",
                        "image/heif": ".heif",
                    }.get(mime, ".bin")
                save_name = datetime.now().strftime("%Y%m%d_%H%M%S_%f") + "_" + orig_name
                save_path = os.path.join(UPLOAD_DIR, save_name)
                with open(save_path, "wb") as out:
                    out.write(raw)
                saved_files.append(save_path)

                exif_dt = _read_exif_datetime_from_bytes(raw)

                ps_time = None
                if idx < len(photos):
                    ps = photos[idx] or {}
                    cand_ps_keys = ["time","takenAt","timestamp","fileCreatedAt","createdAt","created_at","sentAt","sent_at","messageTime","message_time","kakaoTime","kakao_time"]
                    ps_time_str = next((ps.get(k) for k in cand_ps_keys if ps.get(k)), None)
                    if ps_time_str:
                        ps_time = _parse_any_dt(ps_time_str)

                final_dt = exif_dt or ps_time or _dt_from_filename(orig_name)
                data_url = f"data:{f.mimetype or 'image/jpeg'};base64,{base64.b64encode(raw).decode('ascii')}"

                img_dict = {"data": data_url, "filename": orig_name, "originalName": orig_name, "saved_path": save_path}
                if final_dt:
                    img_dict["takenAt"] = final_dt.isoformat(sep=" ")
                    img_dict["timestamp"] = int(final_dt.timestamp() * 1000)
                    img_dict["shotAt"] = img_dict["timestamp"]
                    img_dict["order_ts"] = img_dict["timestamp"]
                    debug_injected.append({"i": idx, "source": "exif|ps|name", "takenAt": img_dict["takenAt"]})
                else:
                    debug_injected.append({"i": idx, "source": "none", "takenAt": ""})
                images.append(img_dict)

            print(f"{'='*60}\n")

            analysis = analyze_images(images, photos_summary=photos)

            # [ì¶”ê°€] Vision ë‹¨ê³„ content_filterì— ê±¸ë¦° ê²½ìš° ë°”ë¡œ ì°¨ë‹¨
            if analysis and analysis.get("unsafe"):
                return jsonify({
                    "ok": True,
                    "body": "ë¶€ì ì ˆí•œ ë‚´ìš©ì´ ê°ì§€ë˜ì–´ ì¼ê¸°ë¥¼ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "category": "general_single",
                    "used": "unsafe_filtered_vision",
                    "moderation": analysis,
                })

            if target_date:  # [ì¶”ê°€]
                try:
                    analysis["date_sequence"] = _shift_date_sequence(analysis.get("date_sequence") or [], target_date)
                    analysis["date_anchor"] = {"mode": "user_target", "target_date": target_date}
                except Exception as _e:
                    analysis["date_anchor_error"] = str(_e)

            # [ì¶”ê°€] ì•ˆì „ì„± í•„í„°
            is_safe, mod_debug = is_content_safe_for_diary(analysis)
            if not is_safe:
                return jsonify({
                    "ok": True,
                    "body": "ë¶€ì ì ˆí•œ ë‚´ìš©ì´ ê°ì§€ë˜ì–´ ì¼ê¸°ë¥¼ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "category": "general_single",
                    "used": "unsafe_filtered",
                    "moderation": mod_debug,
                })

            frames_len = len((analysis or {}).get("frames") or [])

            if analysis and frames_len > 1 and is_food_dominant_multi(analysis):
                try:
                    analysis = enrich_food_structured_for_multi(analysis, images=images, photos_summary=photos)
                    category_hint = "food_multi"
                except Exception as _e:
                    analysis["food_multi_enrich_error"] = str(_e)
                    category_hint = "journey_multi"
            else:
                category_hint = "journey_multi" if (analysis and frames_len > 1) else "general_single"

            # --- ALT êµì°¨ê²€ì¦ ìŠ¤í‚µ íŒë‹¨ (ì¶”ê°€) ---
            food_score = _food_likelihood_score(analysis)
            use_alt = True
            if ALT_SKIP_IF_LOW_FOOD and (food_score < ALT_LOW_FOOD_THRESH):
                use_alt = False

            if use_alt:
                # êµì°¨ê²€ì¦ ë‹¨ê³„
                selected_draft, cv_debug = select_draft_via_cross_validation(analysis, tone, category_hint)
            else:
                # ALT ìŠ¤í‚µ: ê¸°ë³¸ ëª¨ë¸ í•œ ë²ˆë§Œ í˜¸ì¶œ
                selected_draft = draft_diary(analysis, tone, category_hint, text_model=MODEL_TEXT)
                cv_debug = {"used": "primary_only", "reason": "low_food_likelihood", "food_score": food_score}

            # --- ë³´ì • ë‹¨ê³„ ì¡°ê±´ë¶€ ìŠ¤í‚µ (ì¶”ê°€) ---
            if REFINE_SKIP_IF_SHORT and len((selected_draft or "").strip()) < REFINE_MIN_CHARS:
                final_text = selected_draft
                if isinstance(cv_debug, dict):
                    cv_debug["refine"] = "skipped_short_draft"
            else:
                final_text = refine_diary(analysis, selected_draft, tone, category_hint)

            if final_text:
                # CosmosDBì— ì¼ê¸° ì €ì¥
                try:
                    save_result = save_diary(
                        user_id=request.user_id,
                        diary_text=final_text,
                        images=saved_files if 'saved_files' in locals() else [],
                        metadata={
                            'category': category_hint,
                            'tone': tone,
                        }
                    )
                    diary_id = save_result.get('diary_id')
                except Exception:
                    diary_id = None
                return jsonify({
                    "ok": True,
                    "body": final_text,
                    "diary_id": diary_id,
                    "category": category_hint,
                    "used": "vision-3stage",
                    "observations": (analysis or {}).get("frames", []),
                    "ordering_debug": (analysis or {}).get("ordering_debug", []),
                    "date_sequence": (analysis or {}).get("date_sequence", []),
                    "food_fusion": (analysis or {}).get("food_fusion", {}),  # ì¶”ê°€ ë…¸ì¶œ
                    "saved_files": saved_files,
                    "debug_injected": debug_injected,
                    "debug_meta_head": debug_meta_head,
                    "cv_debug": cv_debug
                })
            return jsonify({
                "ok": True,
                "body": random.choice(FALLBACKS),
                "category": category_hint,
                "used": "fallback",
                "saved_files": saved_files,
                "cv_debug": cv_debug
            })

        # 2) JSON ê²½ë¡œ
        data = request.get_json(silent=True) or {}
        tone = data.get("tone") or "ì¤‘ë¦½"
        target_date = (data.get("targetDate") or "").strip()  # [ì¶”ê°€]
        images_raw = (data.get("images") or [])[:MAX_IMAGES]
        # Stage1 íˆ¬ì… ì´ë¯¸ì§€ ìˆ˜ ì»· (ì¶”ê°€)
        images_raw = images_raw[:min(len(images_raw), STAGE1_TOP_N, MAX_IMAGES)]
        photos = data.get("photosSummary") or []
        images_meta = data.get("imagesMeta") or []

        images: list[dict] = []
        debug_injected = []
        debug_meta_head = [{"i": i, "shotAt": (images_meta[i] or {}).get("shotAt")} for i in range(min(len(images_meta), len(images_raw)))]

        print(f"\n{'='*60}")
        print(f"[JSON ì—…ë¡œë“œ] {len(images_raw)}ê°œ ì´ë¯¸ì§€ ìˆ˜ì‹ ")
        print(f"{'='*60}")

        for i, img in enumerate(images_raw):
            item = {"data": img} if not isinstance(img, dict) else img.copy()
            if i < len(images_meta):
                meta = images_meta[i] or {}
                shot = meta.get("shotAt")
                if shot is not None:
                    try:
                        ts_ms = None; dt = None
                        if isinstance(shot, (int, float)):
                            shot_int = int(shot)
                            ts_ms = shot_int if shot_int > 10_000_000_000 else shot_int * 1000
                            dt = datetime.fromtimestamp(ts_ms / 1000.0)
                        elif isinstance(shot, str):
                            dt = _parse_any_dt(shot)
                            if dt: ts_ms = int(dt.timestamp() * 1000)
                        if dt and ts_ms is not None:
                            item["takenAt"]  = dt.isoformat(sep=" ")
                            item["timestamp"]= ts_ms
                            item["shotAt"]   = ts_ms
                            item["order_ts"] = ts_ms
                            debug_injected.append({"i": i, "source": "shotAt", "takenAt": item["takenAt"]})
                        else:
                            debug_injected.append({"i": i, "source": "shotAt_parse_fail", "takenAt": ""})
                    except Exception as e:
                        debug_injected.append({"i": i, "source": "shotAt_exception", "err": str(e)})
                else:
                    debug_injected.append({"i": i, "source": "no_shotAt"})
            else:
                debug_injected.append({"i": i, "source": "no_meta"})
            images.append(item)

        print(f"{'='*60}\n")

        if images:
            try:
                analysis = analyze_images(images, photos_summary=photos)

                # [ì¶”ê°€] Vision ë‹¨ê³„ content_filterì— ê±¸ë¦° ê²½ìš° ë°”ë¡œ ì°¨ë‹¨
                if analysis and analysis.get("unsafe"):
                    return jsonify({
                        "ok": True,
                        "body": "ë¶€ì ì ˆí•œ ë‚´ìš©ì´ ê°ì§€ë˜ì–´ ì¼ê¸°ë¥¼ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                        "category": "general_single",
                        "used": "unsafe_filtered_vision",
                        "moderation": analysis,
                    })

                if target_date:  # [ì¶”ê°€]
                    try:
                        analysis["date_sequence"] = _shift_date_sequence(analysis.get("date_sequence") or [], target_date)
                        analysis["date_anchor"] = {"mode": "user_target", "target_date": target_date}
                    except Exception as _e:
                        analysis["date_anchor_error"] = str(_e)

                # [ì¶”ê°€] ì•ˆì „ì„± í•„í„°
                is_safe, mod_debug = is_content_safe_for_diary(analysis)
                if not is_safe:
                    return jsonify({
                        "ok": True,
                        "body": "ë¶€ì ì ˆí•œ ë‚´ìš©ì´ ê°ì§€ë˜ì–´ ì¼ê¸°ë¥¼ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                        "category": "general_single",
                        "used": "unsafe_filtered",
                        "moderation": mod_debug,
                    })

                frames_len = len((analysis or {}).get("frames") or [])

                if analysis and frames_len > 1 and is_food_dominant_multi(analysis):
                    try:
                        analysis = enrich_food_structured_for_multi(analysis, images=images, photos_summary=photos)
                        category_hint = "food_multi"
                    except Exception as _e:
                        analysis["food_multi_enrich_error"] = str(_e)
                        category_hint = "journey_multi"
                else:
                    category_hint = "journey_multi" if (analysis and frames_len > 1) else "general_single"

                # --- ALT êµì°¨ê²€ì¦ ìŠ¤í‚µ íŒë‹¨ (ì¶”ê°€) ---
                food_score = _food_likelihood_score(analysis)
                use_alt = True
                if ALT_SKIP_IF_LOW_FOOD and (food_score < ALT_LOW_FOOD_THRESH):
                    use_alt = False

                if use_alt:
                    # êµì°¨ê²€ì¦ ë‹¨ê³„
                    selected_draft, cv_debug = select_draft_via_cross_validation(analysis, tone, category_hint)
                else:
                    # ALT ìŠ¤í‚µ: ê¸°ë³¸ ëª¨ë¸ í•œ ë²ˆë§Œ í˜¸ì¶œ
                    selected_draft = draft_diary(analysis, tone, category_hint, text_model=MODEL_TEXT)
                    cv_debug = {"used": "primary_only", "reason": "low_food_likelihood", "food_score": food_score}

                # --- ë³´ì • ë‹¨ê³„ ì¡°ê±´ë¶€ ìŠ¤í‚µ (ì¶”ê°€) ---
                if REFINE_SKIP_IF_SHORT and len((selected_draft or "").strip()) < REFINE_MIN_CHARS:
                    final_text = selected_draft
                    if isinstance(cv_debug, dict):
                        cv_debug["refine"] = "skipped_short_draft"
                else:
                    final_text = refine_diary(analysis, selected_draft, tone, category_hint)

                if final_text:
                    return jsonify({
                        "ok": True,
                        "body": final_text,
                        "category": category_hint,
                        "used": "vision-3stage",
                        "observations": (analysis or {}).get("frames", []),
                        "ordering_debug": (analysis or {}).get("ordering_debug", []),
                        "date_sequence": (analysis or {}).get("date_sequence", []),
                        "food_fusion": (analysis or {}).get("food_fusion", {}),  # ì¶”ê°€ ë…¸ì¶œ
                        "debug_injected": debug_injected,
                        "debug_meta_head": debug_meta_head,
                        "cv_debug": cv_debug
                    })
                return jsonify({
                    "ok": True,
                    "body": random.choice(FALLBACKS),
                    "category": category_hint,
                    "used": "fallback",
                    "cv_debug": cv_debug
                })
            except RateLimitError as e:
                msg = getattr(e, "message", None) or str(e) or "rate_limit"
                retry_ms = None
                body = getattr(e, "body", {}) or {}
                err = body.get("error") if isinstance(body, dict) else {}
                if isinstance(err, dict):
                    retry_ms = err.get("retry_after")
                if retry_ms is None:
                    match = re.search(r"try again in\s+(\d+)\s*ms", msg, re.I)
                    if match:
                        retry_ms = int(match.group(1))
                return jsonify({"ok": False, "error": "rate_limit", "message": msg, "retry_after_ms": retry_ms}), 429
            except Exception as e:
                traceback.print_exc()
                category_hint = "journey_multi" if len(images) > 1 else "general_single"
                return jsonify({"ok": True, "body": random.choice(FALLBACKS), "category": category_hint, "used": "fallback", "error": str(e)})

        # 3) ì´ë¯¸ì§€ ì—†ìœ¼ë©´ photosSummaryë¡œ ìµœì†Œ ë‹¨ì„œ ìƒì„±
        lines: list[str] = []
        for p in photos:
            base = " ".join([(p.get("place") or "").strip(), (p.get("time") or "").strip(), (p.get("weather") or "").strip(), (p.get("desc") or "").strip()]).strip()
            base = clean_inline(base)
            if base: lines.append(base)

        if lines:
            text = generate_from_lines(lines, tone)
            if text:
                return jsonify({"ok": True, "body": text, "category": decide_category_from_lines(lines), "used": "summary-lines", "observations": lines})

        return jsonify({"ok": False, "error": "no_input", "message": "ì‚¬ì§„ì„ ë„£ê±°ë‚˜ ìµœì†Œ ë‹¨ì„œë¥¼ ì œê³µí•˜ì„¸ìš”."}), 400

    except Exception as e:
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500

@app.get("/health")
def health():
    return {"ok": True}

# ---------------- CORS ----------------
@app.after_request
def add_cors_headers(resp):
    resp.headers["Access-Control-Allow-Origin"] = "*"
    resp.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization"
    resp.headers["Access-Control-Allow-Methods"] = "GET,POST,OPTIONS"
    resp.headers["Access-Control-Allow-Private-Network"] = "true"
    return resp

@app.route("/api/auto-diary", methods=["OPTIONS"])
@app.route("/api/signup", methods=["OPTIONS"])
@app.route("/api/login", methods=["OPTIONS"])
@app.route("/api/logout", methods=["OPTIONS"])
@app.route("/api/me", methods=["OPTIONS"])
@app.route("/api/diaries", methods=["OPTIONS"])
@app.route("/api/diaries/<diary_id>", methods=["OPTIONS"])
@app.route("/api/user/me", methods=["OPTIONS"])                    # âœ… ì¶”ê°€!
@app.route("/api/user/change-password", methods=["OPTIONS"])       # âœ… ì¶”ê°€!
@app.route("/api/user/delete-account", methods=["OPTIONS"]) 
@app.route("/api/send-verification", methods=["OPTIONS"])
@app.route("/api/verify-code", methods=["OPTIONS"])
@app.route("/api/forgot-password", methods=["OPTIONS"])
@app.route("/api/reset-password", methods=["OPTIONS"])
def _preflight_auth(diary_id=None):
    return ("", 200)
def _preflight(diary_id=None):
    return ("", 200)

# ---------------- ì‹¤í–‰ ----------------
if __name__ == "__main__":
    print("\n===========================================")
    print("ì„œë²„ ì‹œì‘ â†’ http://127.0.0.1:5000")
    print("ALT_TEXT_MODEL =", ALT_TEXT_MODEL)
    print("===========================================\n")
    app.run(host="0.0.0.0", port=5000, debug=False)